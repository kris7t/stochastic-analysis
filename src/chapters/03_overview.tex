\chapter{Overview}
\label{chap:overview}

\section{General stochastic analysis workflow}

\begin{figure}
  \centering
  \begin{tikzpicture}[
    start chain,
    every node/.style={
      on chain,join,
      text width=2.1cm,minimum height=1.2cm,align=center,
      draw,tdk highlight,rounded corners=0.25cm},
    node distance=1cm,
    every join/.style={-{Latex},draw}]

    \node {State space exploration};
    \node {Descriptor generation};
    \node {Numerical solution};
    \node {Reward calculation};
  \end{tikzpicture}
  \caption{The general stochastic analysis workflow.}
  \label{fig:overview:general:workflow}
\end{figure}

The tasks performed by stochastic analysis tools that operate on
higher level formalisms can be often structured as follows
(\vref{fig:overview:general:workflow}):
\begin{enumerate}
\item \emph{State space exploration.} The reachable state space of the
  higher level model, for example stochastic automata network or
  stochastic Petri net is explored to enumerate the possible behaviors of the model $S$. If the model is hierarchically partitioned, this step includes the exploration of the local state
  spaces of the component as well as the possible global combinations
  of states.

  If the set of reachable states is infinite, only special algorithms,
  e.g.~matrix geometric methods~\citep{haverkort1995matrix} may be
  employed later in the workflow. In this work, we restrict our
  attention to finite cases.
\item \emph{Descriptor generation.} The infinitesimal generator matrix
  $Q$ of the Markov chain $X(t)$ defined over $S$ is built. If the
  analyzed formalism is a Markov chain, $Q$ is readily
  given. Otherwise, this matrix contains the transition rates between
  reachable states, which are obtained by evaluating rate expressions
  given in the model.
\item \emph{Numerical solution.} Numerical algorithms are ran on the
  matrix $Q$ for steady-state solutions $\vec{\uppi}$, transient
  solutions $\vec{\uppi}(t)$, $\vec{L}(t)$ or \textls{MTFF} measures.
\item \emph{Reward calculations.} The studied performance measures are
  calculated from the output of the previous step. This includes
  calculation of steady-state and transient rewards and sensitivities
  of the rewards. Additional algebraic manipulations (for example, the
  calculation of the ratio of an instantenous and accumulated reward)
  may be provided to the modeler for convenience.

\end{enumerate}

In stochastic model checking, where the desired system behaviors are
expressed in stochastic temporal logics%
~\citep{bianco1995model,baier1999approximative}, these analytic steps
are called as subroutines to evaluate propositions. In the synthesis and
optimization of stochastic models%
~\citep{DBLP:journals/jacm/ChatterjeeHJ015}, the workflow is executed
as part of the fitness functions.

\subsection{Challenges}

The implementation of the stochastic analysis workflow poses several
challenges.

Handling of large models is difficult due to the phenomenon of
\enquote{state space explosion}. As the size of the model grows,
including the number of components, the number of reachable spaces can
grow exponentially.

Methods such as the \emph{saturation} algorithm~\citep{Ciardo:2006}
were developed to efficiently explore and represent large state
spaces. However, in stochastic analysis, the generator matrix $Q$ and
several vectors of real numbers with lengths equal to the state space
size must be stored in addition to the state space. This necessitates
the use of further decomposition techniques for data storage.

The convergence of the numerical methods depends on the structure of
the model and the applied matrix decomposition. In addition, the memory
requirements of the algorithms may constrain the methods that can be
employed. As various numerical algorithms for stochastic analysis
tasks are known with different characteristics, it is important to
allow the modeler to select the algorithm suitable for the properties
of the model, as well as the decomposition method and hardware environment.

The vector operations and vector-matrix products that are performed by
the numerical algorithms can also be performed in multiple ways. For
example, multiplications with matrices can be implemented either
sequentially or in parallel. Large matrices benefit from
parallelization, while for small matrices managing
multiple tasks yields overhead. Distributed or \textls{GPU}
implementations are also possible, albeit they are missing from the
current version of our framework.

\section{Our workflow in PetriDotNet}
\label{chap:overview:sec:our-workflow}

\begin{figure}
  \centering
  \begin{tikzpicture}[
    data/.style={
      text width=2.1cm,minimum height=1.2cm,align=center,
      draw,tdk highlight
    },
    activity/.style={rounded corners=0.25cm}
    ]
    \matrix [every node/.append style={data},column sep=1cm,row sep=0.65cm] {
      \node (model) {Stochastic Petri Net};
      & \node [activity] (sse) {State space exploration};
      & \node [activity] (gen) {Generator construction};
      & \node (ds) {Data structure}; \\
      & \node (sspn) {Model partition};
      & & \node [activity] (numeric) {Numerical algorithms}; \\
      & & \coordinate (calc-input);
      & \node [activity] (calc) {Reward calculation}; \\
    };
    \node [yshift=0.925cm,data] (reward) at (calc-input)
    {Reward config.};
    \node [yshift=-0.925cm,data] (sensitivity) at (calc-input)
    {Sensitivity parameters};

    \draw [-{Latex}] (model) edge (sse) (sse) edge (gen)
    (sspn) edge (sse) (gen) edge (ds)
    (ds) edge [transform canvas={xshift=0.325cm}] (numeric)
    (numeric) edge [transform canvas={xshift=-0.325cm}] (ds)
    (numeric) edge (calc) (reward) edge (calc)
    (sensitivity) edge (calc);

    \draw ($(ds.north west)+(-0.325cm,0.325cm)$)
    rectangle ($(numeric.south east)+(0.325cm,-0.325cm)$);
    \node [above=0.4cm of ds, text width=4cm,align=center] {%
      Analysis with\\configurable operations};

    %\draw ($(ds.south)+(-0.7cm,-0.325cm)$) edge
    %($(ds.south)+(0.7cm,-0.325cm)$) node [left]
    %{Configurable operations};
  \end{tikzpicture}
  \caption{Configurable stochastic analysis workflow.}
  \label{fig:overview:our:workflow}
\end{figure}

``\textsc{PetriDotNet} is a framework for the editing, simulation and
analysis of Petri nets. The framework is developed by the Fault
Tolerant Systems Research Group at the Budapest University of
Technology and Economics.'' \citep{Petridotnet}

The implementation of the general stochastic analysis workflow in
\textsc{PetriDotNet} is illustrated in
\cref{fig:overview:our:workflow}. The models are specified using the
stochastic Petri net (\textls{SPN}) formalism%
~\citep{murata1989petri,DBLP:conf/apn/Marsan88}, while engineering
measures to be calculated are expressed as \textls{SPN} performance
measures. Both explicit and symbolic state space exploration and
storage is supported, including symbolic hierarchical state space
decomposition for block Kronecker generator matrices.

The workflow is fully \emph{configurable}, which means that the
modeler may combine the available algorithms for the analysis steps
arbitrarily. In addition, implementations of the linear algebra
operations performed by the algorithms may be replaced at
runtime.

\section{Architecture}

\begin{figure}
  \centering
  \begin{tikzpicture}
    \node (layers) [text width = 7.5cm,
    rectangle split, rectangle split parts = 4,
    align = center,
    inner sep = 0pt,
    draw,
    rectangle split part fill = {white, white, black!20, black!20}] {
      \begin{minipage}{0.9\linewidth}%
        \vspace*{7pt}\centering%
        Stochastic Petri net analysis: \\
        $\bullet$~{State space exploration} \\
        $\bullet$~{Translation of \textls{SPN} measures}%
        \vspace*{7pt}%
      \end{minipage}
      \nodepart{two}%
      \begin{minipage}{0.9\linewidth}%
        \vspace*{7pt}\centering%
        Stochastic automata network analysis: \\
        $\bullet$~{Descriptor generation}\\
        $\bullet$~{Reward and sensitivity calculation}%
        \vspace*{7pt}%
      \end{minipage}
      \nodepart{three}%
      \begin{minipage}{0.9\linewidth}%
        \vspace*{7pt}\centering%
        Numerical algorithms:\\
        $\bullet$~{LU decomposition, power iteration, Jacobi,
          Gauss--Seidel, group iteration, \textls{BiCGSTAB}}\\
        $\bullet$~{Uniformization, \textls{TR-BDF2}}%
        \vspace*{7pt}%
      \end{minipage}
      \nodepart{four}%
      \begin{minipage}{0.5\linewidth}%
        \vspace*{7pt}\centering%
        Matrix-vector\\
        data structure%
        \vspace*{7pt}%
      \end{minipage}%
      \vrule
      \begin{minipage}{0.5\linewidth}%
        \vspace*{7pt}\centering%
        Configurable operations%
        \vspace*{7pt}%
      \end{minipage}%
    };

    \node [right=-8pt of layers.west,rotate=90,anchor=south,xshift=10pt]
    {Analysis workflow};

    \begin{pgfonlayer}{bg}
      \node (pdn) at (layers.south east) [anchor=south east,minimum
      width=10cm, minimum height=8.75cm, draw, dashed] {};

      \node (workflow) at (layers.south east) [anchor=south east,minimum
      width=8.75cm, minimum height=8.25cm, draw, tdk highlight] {};
    \end{pgfonlayer}

    \node [right=-8pt of workflow.west,rotate=90,anchor=south,xshift=10pt]
    {\textsc{PetriDotNet}};

    \draw ($(layers.east)+(5pt,0pt)$)
    edge [decorate,decoration={brace,amplitude=10pt}]
    node [right,xshift=10pt] {Backend}
    ($(layers.south east)+(5pt,0pt)$);

    \draw ($(layers.north east)+(5pt,0pt)$)
    edge [decorate,decoration={brace,amplitude=10pt}]
    node [right,xshift=10pt] {Frontend}
    ($(layers.east)+(5pt,15pt)$);

  \end{tikzpicture}
  \caption{Layered architecture for configurable stochastic analysis.}
  \label{fig:overview:layered}
\end{figure}

\Cref{fig:overview:layered} shows the architecture of the configurable
stochastic analysis module.
\begin{itemize}
\item The user interacts with the stochastic \emph{analysis
    workflow} runner.

  The model, its parameters and its stochastic behavior as transition
  rates of timed transitions is specified and engineering measures of
  interest (e.g.~performability, availability, reliability,
  dependability) are defined with \textls{SPN} rewards. Afterwards,
  the analysis workflow can be initiated by selecting the analysis
  type (steady-state, sensitivity, transient, \textls{MTFF}), the used
  algorithms and the engineering measures to compute. The workflow
  runner instantiates and executes the components which are required
  to complete the analysis and displays the results.

  Numerical analysis algorithms most suitable for the analyzed model
  and executing hardware may be selected by the user. Moreover,
  low-level linear algebra operations, for example, parallel or
  sequential algorithms for matrix products, may be also selected for
  every step in the workflow.
\end{itemize}
The stochastic analysis problem is translated into numerical problems
by the ``frontend'' part of the analysis module:
\begin{itemize}
\item The \emph{stochastic Petri net analysis} modules translate the
  stochastic behavior of Petri net into generic data structures. The
  partition of the model defines the stochastic automata of the
  \textls{SAN} representation of the model. The algebraic expressions
  that specify transition rates and rewards are evaluated, thus lower
  level components only work with transition rates and their
  derivatives.

  Symbolic state space exploration is performed by the
  \emph{saturation} algorithm~\citep{ciardo2001saturation}, which is
  provided by the symbolic analysis component of
  \textsc{PetriDotNet}~\citep{TDK2010_Darvas}. Petri nets with
  inhibitor arcs are supported, but transitions with priority
  (including non-timed transitions) cannot be used/

  Reward expressions that refer to subsets of the reachable state space
  defined by Computation Tree Logic
  (\textls{CTL})~\citep{DBLP:journals/fac/HanssonJ94} are also
  evaluated by the symbolic analysis component. Therefore,
  \textls{CTL} rewards cannot be used with explicit state space
  representation algorithms.

\item The \emph{stochastic automata network analysis} module
  implements explicit and symbolic procedures for infinitesimal
  generator matrix composition and reward calculation. This component
  does not depend on the Petri net formalism and may be reused for
  different formalisms.

  The matrices $Q$ and $V_i$, that is, the generator matrix and its
  partial derivatives may be stored as a dense or sparse array or a
  block Kronecker matrix using the object model defined by the
  matrix-vector data structure. Linear algebra operations during the
  generator composition, for example, calculation of the diagonal
  entries of $Q$, are performed by the operation framework supporting
  the data structure.

  Numerical solution algorithms, such as linear equation solvers and
  transient integrators are called to derive the steady state and
  transient distributions of the Markov chain and its sensitivities.

  The final task performed by the frontend is the calculation of the
  reward values, which uses both linear algebra operations and
  symbolic iteration over the results of the \textls{CTL} evaluator.
\end{itemize}
The analysis ``backend'' serves as a library of matrix--vector data
structured, linear algebra operations and numerical solution
algorithms:
\begin{itemize}
\item \emph{Numerical algorithms} implement solution finding for linear
  equations and Markovian transient initial value problems. The
  algorithms are implemented generically whenever possible, so that no
  assumptions are made about the structure of matrices unless
  necessary due to mathematical or performance reasons. This is
  achieved by the definition of a (non-orthogonal) set of operations
  on the matrix-vector data structure. The operations may be replaced
  at runtime for flexibility, for example, different implementations
  of operations may be used for different algorithms in the same
  workflow.

\item The \emph{matrix-vector data structure} provides an interface
  for storing various linear algebra objects.

  In addition to dense and sparse arrays, wrappers are provided to
  access parts of matrices and vectors and to build expression trees
  out of smaller matrices. Hence, matrices such as block Kronecker
  infinitesimal generators (\vref{eq:genstor:explicit:block:block})
  can be stored as a collection of small sparse matrices in a nested
  expression tree.

  While current the frontend only generates simple arrays and block
  Kronecker matrices, and descriptor format may be used as long as it
  can be expressed as expression trees.

  The data structure only provides storage, any calls to linear
  algebra operations are delegated to the configurable operation
  context.

\item The \emph{configurable operation context} provides and
  dispatches the implementations of linear algebra operations, such as
  matrix-vector product or vector addition.

  Operations are specific to the data structure and may use multiple
  dispatch call semantics. For example, an operation can be defined
  that handles the multiplication of a block matrix and a constant
  vector, and stores the result in vector backed by a linear
  array. In addition to type information, the dispatch may use
  addition runtime properties, such as the length of a vector to
  select the appropriate implementation.

  The dispatch rules may be modified at runtime. For example, parallel
  execution may be replaced with sequential during the execution of
  algorithms that achieve parallelization through other means.

  Contrast operations with numerical algorithms, which are higher level
  procedures that solve a particular numerical problem on a wide range
  of data structures by delegation to a non-orthogonal set of specific
  operations.
\end{itemize}

The stochastic analysis backed, which was developed by the author,
comprise the topic of present work. \Cref{fig:overview:layered} shows
its three components shaded in gray.

Manipulations performed by the frontend components on the input Petri
net models the generated descriptors are discussed in this thesis only
briefly. We refer the interested reader to
\cite{TDK2015_Klenik_Marussy} for an overview of the whole
\textsc{PetriDotNet} stochastic analysis component.

\section{Current status}

In this section we briefly summarize the results of the backend
development effort.

\subsection{Data structures}

The data structure can represent infinitesimal generator matrices of
continuous-time Markov chains with possible stochastic automata
network structure as dense or sparse arrays, sums of Kronecker
products and block Kronecker matrices.

Additional matrix decompositions may be created as algebraic
expression trees using from the provided expression primitives of
block matrices, linear combinations and Kronecker products. Moreover,
the framework may be extended with further primitives simply by
implementing some interfaces.

The linear algebra operations framework provides the most commonly
used vector and matrix operations, including addition and scaling,
scalar products and vector-matrix products. Matrix-matrix products are
not provided due to the impossibility of fast and compact evaluation
of such products with matrices of general decomposed forms.

All provided operations are listed in \vref{tab:operations:operations}
in \cref{chap:operations}, where the data structure and operations are
discussed.

\subsection{Numerical algorithms}

\begin{table}
  \caption{Linear equation solvers supported by our framework.}
  \centering
  \begin{tabular}{@{}llcccc@{}}
    \toprule
    & & memory & parallel & uses inner & block \\[-0.5ex]
    & \multicolumn{1}{c}{see} & usage & impl. & solver & matrix \\
    \midrule
    \textls{LU} decomposition & p.~\pageref{ssec:algorithms:lu} & very high & -- & -- & -- \\
    Power method & p.~\pageref{ssec:algorithms:power} & moderate & $\checkmark$ & -- & $\checkmark$ \\
    Jacobi over-relaxation & p.~\pageref{ssec:algorithms:jgs} & moderate & $\checkmark$ & -- & $\checkmark$ \\
    Gauss--Seidel over-relaxation & p.~\pageref{ssec:algorithms:jgs} & very low & -- & -- & $\checkmark$ \\
    Group Jacobi & p.~\pageref{sec:algorithms:group-jgs} & moderate & $\checkmark$ & $\checkmark$ & required \\
    Group Gauss--Seidel & p.~\pageref{sec:algorithms:group-jgs} & low & -- & $\checkmark$ & required \\
    \textls{BiCGSTAB} & p.~\pageref{ssec:algorithms:bicgstab} & high &
                                                                       $\checkmark$ & -- & $\checkmark$ \\
    \textls{IDR($s$)STAB($l$)} &
                                          p.~\pageref{ssec:algorithms:idrstab}
      & \multicolumn{4}{c@{}}{Work in progress} \\
    \bottomrule
  \end{tabular}
  \label{tab:overview:our:linear}
\end{table}

\begin{table}
  \caption{Transient solvers supported by our framework.}
  \centering
  \begin{tabular}{@{}llcccc@{}}
    \toprule
    & & instantenous & accumulated & uses inner & block \\[-0.5ex]
    & \multicolumn{1}{c}{see} & distribution & distribution & solver & matrix \\
    \midrule
    Uniformization & p.~\pageref{ssec:algorithms:uniformization} & $\checkmark$ & $\checkmark$ & -- & $\checkmark$ \\
    \textls{TR-BDF2} & p.~\pageref{ssec:algorithms:trbdf2} & $\checkmark$ & not impl. & $\checkmark$ & not impl. \\
    \bottomrule
  \end{tabular}
  \label{tab:overview:our:transient}
\end{table}

Seven linear equation solver algorithms were implemented for
steady-state, sensitivity and \textls{MTFF} problems:
\textls{LU} decomposition, power iteration, Jacobi over-relaxation,
Gauss--Seidel over-relaxation, group Jacobi, group Gauss--Seidel and
\textls{BiCGSTAB}. Group Jacobi and Gauss--Seidel require a block
matrix, while the other algorithms may run on any matrix.

Special attention is paid to the root finding of singular systems with
zero right vectors, i.e.~the determination of the nullspace of a
matrix for systems arising from Markovian steady-state
problems. Nonsingular problems are solved in steady-state sensitivity
analysis and mean-time-to-failure analysis.

The current research and development effort focuses on the integration
of a solver based on \textls{IDR($s$)STAB($l$)}%
~\citep{sleijpen2010exploiting}, a Krylov subspace algorithm which
generalizes the \textls{BiCGSTAB} algorithm. As the algorithm needs
adaptation for singular matrices, it is currently not suitable for
production use in Markovian analysis due to numerical breakdowns and
instability.

Our modifications to \textls{IDR($s$)STAB($l$)} are shown in
\vref{alg:algorithms:idrstab:idrstab,alg:algorithms:idrstab:idr,%
  alg:algorithms:idrstab:gmres}, which were found to improve
convergence behavior in steady-state analysis problems. However, the
stability is still lacking, as we observed in
\vref{sec:evaulations:idrstab}.

Two solution algorithms, uniformization and \textls{TR-BDF2}
are available for transient analysis. Accumulated rewards can be
calculated by uniformization only, while \textls{TR-BDF2} provides
robustness for otherwise difficult to handle stiff Markov chains.

Important considerations in solver selection are convergence
properties and memory requirements. Matrix decompositions
can reduce the storage space needed by the matrix $Q$ by orders of
magnitudes. We store all elements of probability vectors
explicitly. Therefore, one should pay close attention to the number
of temporary vectors used in the algorithm in order to avoid
excessive memory consumption.

Numerical algorithms supported by our framework are further discussed
in \cref{chap:algorithms}. Linear equations solvers for steady-state
\CTMC\ analysis are shown in \cref{tab:overview:our:linear}, while
transient solvers are shown in \cref{tab:overview:our:transient}.
