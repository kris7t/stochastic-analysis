\chapter{Background}
\label{chap:background}

In this section we overview the basic formalisms and scope of our
work. \textbf{TODO}

\section{Continuous-time Markov chains}

Continuous-time Markov chains are mathematical tools for describing the
behavior of systems in countinous time where the stochastic behavior of
the system only depends on its current state.

\begin{dfn}
  A \emph{Continuous-time Markov Chain} \paren{\CTMC}
  $X(t) \in S, t \ge 0$ over the finite state
  space $S = \{0, 1, \ldots, n - 1\}$ is a continuous-time random
  process with the \emph{Markovian} or memoryless property:
  \begin{multline}\allowdisplaybreaks[0]
    \Pr(X(t_k) = x_k \mid X(t_{k - 1}) = x_{k - 1}, X(t_{k -
      2}) = x_{k - 2}, \ldots, X(t_{0}) = x_{0}) \\
    = \Pr(X(t_k) = x_k \mid X(t_{k - 1}) = x_{k - 1}) \text,
  \end{multline}
  where $t_0 \le t_1 \le \cdots \le t_k$ and $X(t_k)$ is a random variable denoting the current state of the \CTMC\ at time $t_k$. A \CTMC\ is said to be
  \emph{time-homogenous} if it also satisfies
  \begin{equation}
    \Pr(X(t_k) = x_k \mid X(t_{k - 1}) = x_{k - 1}) = \Pr(X(t_k - t_{k -
      1}) = x_k \mid X(0) = x_{k - 1}) \text,
  \end{equation}
  i.e.~it is invariant to time shifting.
\end{dfn}

In this report we will restrict our attention to time-homogenous \CTMC
s over finite state spaces. The state probabilities of these
stochastic processes at time $t$ form a finite-dimensional vector
$\vec{\uppi}(t) \in \RR^n$,
\begin{equation}
  \pi(t)[x] = \Pr(X(t) = x)
\end{equation}
that satisfies the differential equation
\begin{equation}
  \label{eq:background:ctmc:diffeq}
  \frac{\dd \vec{\uppi}(t)}{\dd t} = \vec{\uppi}(t) \, Q
\end{equation}
for some square matrix $Q$. The matrix $Q$ is called the
\emph{infinitesimal generator matrix} of the \CTMC\ and can be
interpreted as follows:
\begin{itemize}
\item The diagonal elements $q[x, x] < 0$ describe the holding times
  of the \CTMC. If $X(t) = x$, the \emph{holding time}
  $h_x = \inf \{ h > 0 : X(t) = x, X(t + h) \ne x \}$ spent in state $x$ is
  exponentially distributed with rate $\lambda_x = -q[x, x]$. If
  $q[x, x] = 0$, then no transitions are possible from state $x$ and
  it is said to be \emph{absorbing}.
\item The off-diagonal elements $q[x, y] \ge 0$ describe the state
  transitions. In state~$x$ the \CTMC\ will jump to state~$y$ at the
  next state transition with probability $-q[x, y] / q[x, x]$.
  Equivalently, there is expontentially distributed countdown in the
  state $x$ for each $y : q[x, y] > 0$ with \emph{transition rate}
  $\lambda_{xy} = q[x, y]$. The first countdown to finish will trigger
  a state change to the corresponding state $y$. Thus, the \CTMC\ is a
  transition system with exponentially distributed timed transitions.
\item Elements in each row of $Q$ sum to $0$, hence it satisfies
  $Q \vec{1}^\T = \vec{0}^\T$.
\end{itemize}

For more algebraic properties of infinitesimal generator matrices, we
refer to \citet{plemmons1979nonnegative,stewart1994introduction}.

A state $y$ is said to be \emph{reachable} from the state $x$
($x \reachto y$) if there exists a sequence of states
\begin{equation}
  x = z_1, z_2, z_3, \ldots, z_{k - 1}, z_k = y
\end{equation}
such that $q[z_i, z_{i + 1}] > 0$ for all $i = 1, 2, \ldots, k -
1$.
If $y$ is reachable from $x$ for all $x, y \in S$ $y$, the Markov chain
is said to be \emph{irreducible}.

The \emph{steady-state probability distribution}
$\vec{\uppi} = \lim_{t \to \infty} \vec{\uppi}(t)$ exists and is
independent from the \emph{initial distribution}
$\vec{\uppi}(0) = \vec{\uppi}_0$ if and only if the finite \CTMC\ is
irreducible. The steady-state distribution satisfies the linear
equation
\begin{equation}
  \label{eq:background:ctmc:steadystate}
  \frac{\dd \vec{\uppi}}{\dd t} = \vec{\uppi} \, Q = \vec{0},
  \quad \vec{\uppi} \vec{1}^\T = 1 \text.
\end{equation}

\begin{figure}
  \begin{minipage}{.49\linewidth}
    \centering
    \begin{tikzpicture}
      \matrix [column sep=1.5cm, every node/.style={inner
        sep=0pt,minimum size=.85cm, draw,circle,tdk highlight}] {
        \node (s0) {0}; & \node (s1) {1}; & \node (s2) {2}; \\
      }; \draw [every edge/.append style={-{Latex},bend left}, every
      node/.append style={above}] (s0) edge node {$\lambda_1$} (s1)
      (s1) edge node {$\lambda_2$} (s2) (s2) edge node {$\mu_2$} (s1)
      (s1) edge node {$\mu_1$} (s0) (s2) edge [bend left=45] node
      {$\mu_3$} (s0);
    \end{tikzpicture}
  \end{minipage}
  \begin{minipage}{.49\linewidth}
    \centering
    $\begin{blockarray}{rccc}
      & 0 & 1 & 2 \\
      \begin{block}{r(ccc)}
        0 & -\lambda_1 & \lambda_1 & 0 \\
        Q = 1 & \mu_1 & -\lambda_2 - \mu_1 & \lambda_2 \\
        2 & \mu_3 & \mu_2 & -\mu_2 - \mu_3 \\
      \end{block}
    \end{blockarray}$
    \vspace{0.5cm}
  \end{minipage}
  \caption{Example \CTMC\ with 3 states and its generator matrix.}
  \label{fig:background:ctmc:repair}
\end{figure}

\begin{example}
  \Cref{fig:background:ctmc:repair} shows a \CTMC\ with $3$
  states. The transitions from state $0$ to $1$ and from $1$ to $2$
  are associated with exponentially distributed countdowns with rates
  $\lambda_1$ and $\lambda_2$ respectively, while transitions in the
  reverse direction have rates $\mu_1$ and $\mu_2$. The transition
  form state $2$ to $0$ is also possible with rate $\mu_3$.
  
  The rows \paren{corresponding to source states} and
  columns \paren{destination states} of the infinitesimal generator
  matrix $Q$ are labeled with the state numbers. The diagonal element
  $q[1, 1]$ is $-\lambda_2 - \mu_1$, hence the holding time in state
  $1$ is exponentially distributed with rate $\lambda_2 + \mu_1$. The
  transition from state $1$ to $0$ is taken with probability
  $-q[1, 0] / q[1, 1] = \mu_1 / (\lambda_2 + \mu_1)$, while the
  transition to $2$ is taken with probability
  $\lambda_2 / (\lambda_2 + \mu_1)$.

  The \CTMC\ is irreducible, because every state is reachable from
  every other state. Therefore, there is a unique steady-state
  distribution $\vec{\uppi}$ independent from the initial distribution
  $\vec{\uppi}_0$.
\end{example}

\subsection{Markov reward models}

Continuous-time Markov chains may be employed in the estimation of
performance measures of models by defining \emph{rewards} that
associate \emph{reward rates} with the states of a \CTMC. The
reward rate random variable $R(t)$ can describe performance
measures defined at a single point of time, such as resource
utilization or probability of failure, while the \emph{accumulated
  reward} random variable $Y(t)$ may correspond to performance
measures associated with intervals of time, such as total downtime.

\begin{dfn}
  A \emph{Continuous-time Markov Reward Process} over a finite state
  space $S = \{0, 1, \ldots, n - 1\}$ is a pair $(X(t), \vec{r})$,
  where $X(t)$ is a \CTMC\ over $S$ and $\vec{r} \in \RR^n$ is a
  \emph{reward rate vector}.
\end{dfn}

The element $r[x]$ of the reward vector is a momentary reward rate in
state $x$, therefore the reward rate random variable can be written as
$R(t) = r[X(t)]$. The accumulated reward until time $t$ is defined by
\begin{equation}
  Y(t) = \int_{0}^t R(\tau) \, \dd \tau \text.
\end{equation}

The computation of the distribution function of Y(t) is a
computationally intensive task (a summary is available at \citep[Table
1]{RACZ02h}), while its mean, $\Ex Y(t)$, can be computed
efficiently as discussed below.

Given the initial probability distribution vector
$\vec{\uppi}(0) = \vec{\uppi}_0$ the expected value of the reward rate
at time $t$ can be calculated as
\begin{equation}
  \label{eq:background:ctmc:reward}
  \Ex R(t) = \sum_{i = 0}^{n - 1} \pi(t)[i] r[i] = \vec{\uppi}(t)
  \, \vec{r}^\T \text,
\end{equation}
which requires the solution of the initial value problem%
~\citep{DBLP:journals/cor/Grassmann77,reibman1989markov}
\begin{equation}
  \label{eq:background:ctmc:transient-ivp}
  \frac{\dd \vec{\uppi}(t)}{\dd t} = \vec{\uppi}(t) \, Q, \quad
  \vec{\uppi}(0) = \vec{\uppi}_0
\end{equation}
to form the inner product $\Ex R(t) = \vec{\uppi}(t) \, \vec{r}^\T$.

To obtain the expected steady-state reward rate (if it exists) the
linear equation~\eqref{eq:background:ctmc:steadystate} should be
solved instead of \cref{eq:background:ctmc:transient-ivp} in order to
acquire the steady-state probability vector $\vec{\uppi}$. The
computation of the reward value proceeds by
\cref{eq:background:ctmc:reward} in the same way as in transient
analysis.

The expected value of the accumulated reward is
\begin{align}
  \Ex Y(t) &= \Ex\mleft[ \int_0^t R(\tau) \,\dd\tau \mright] =
             \int_0^t \Ex[R(\tau)] \,\dd\tau \\
           &= \int_0^t \sum_{i = 0}^{n - 1} \pi(\tau)[i] r[i]
             \,\dd\tau = \sum_{i = 0}^{n - 1} \int_0^t \pi(\tau)[i]
             \,\dd\tau \, r[i] \\
           &= \int_0^t \vec{\uppi}(t) \,\dd\tau \, \vec{r}^\T =
             \vec{L}(t) \, \vec{r}^\T \text,
\end{align}
where $\vec{L}(t) = \int_0^t \vec{\uppi}(t) \,\dd\tau$ is the accumulated
probability vector, which is the solution of the initial value
problem~\citep{reibman1989markov}
\begin{equation}
  \label{eq:background:ctmc:L-ivp}
  \frac{\dd \vec{L}(t)}{\dd t} = \vec{\uppi}(t), \quad \frac{\dd
    \vec{\uppi}(t)}{\dd t} = \vec{\uppi}(t) \, Q, \quad
  \vec{L}(0) = \vec{0}, \quad \vec{\uppi}(0) = \vec{\uppi}_0.
\end{equation}

\begin{example}
  Let $c_0$, $c_1$ and $c_2$ denote operating costs per unit time
  associated with the states of the \CTMC\ in
  \cref{fig:background:ctmc:repair}. Consider the Markov reward
  process $(X(t), \vec{r})$ with reward rate vector
  \begin{equation}
    \vec{r} = \begin{pmatrix} c_0 & c_1 & c_2 \end{pmatrix} \text.
  \end{equation}
  The random variable $R(t)$ describes the momentary operating cost,
  while $Y(t)$ is the total operating expenditure until time $t$. The
  steady-state expectation of $R$ is the average maintenance cost per
  unit time of the long-running system.
\end{example}

\subsection{Sensitivity}

Sensitivity analysis is widely used to assess the robustnes of information systems.
Consider a reward process $(X(t), \vec{r})$ where both the
infinitesimal generator matrix $Q(\vec{\uptheta})$ and the reward rate
vector $\vec{r}(\vec{\uptheta})$ may depend on some \emph{parameters}
$\vec{\uptheta} \in \RR^m$. The \emph{sensitivity} analysis of the
rewards $R(t)$ may reveal performance or reliability bottlenecks of
the modeled system and help designers in achieving desired performance measures and robustnes values.

\begin{dfn}
  The \emph{sensitivity} of the expected reward rate~$\Ex R(t)$ to the
  parameter~$\theta[i]$ is the partial derivative
  \begin{equation}
    \frac{\partial \Ex R(t)}{\partial \theta[i]} \text.
  \end{equation}
\end{dfn}

Considering parameters with high absolute sensitivity the model reacts to the changes of those parameters more prominently, therefore they can be promising directions of system optimization.

To calculate the sensivity of $\Ex R(t)$, the partial derivative of
both sides of \cref{eq:background:ctmc:reward} is taken, yielding
\begin{equation}
  \label{eq:background:ctmc:sensitivity:productrule}
  \frac{\partial \Ex R(t)}{\partial \theta[i]} = \frac{\partial
    \vec{\uppi}(t)}{\partial \theta[i]} \vec{r}^\T + \vec{\uppi}(t)
  \mleft(\frac{\partial \vec{r}}{\partial \theta[i]}\mright)^\T =
  \vec{s}_i(t) \, \vec{r}^\T + \vec{\uppi}(t)
  \mleft(\frac{\partial \vec{r}}{\partial \theta[i]}\mright)^\T \text,
\end{equation}
where $\vec{s}_i$ is the sensitivity of $\vec{\uppi}$ to the parameter
$\theta[i]$.

In transient analysis, the sensitivity vector $\vec{s}_i$ is the
solution of the initial value problem
\begin{equation}
  \frac{\dd \vec{s}_i(t)}{\dd t} = \vec{s}_i(t) Q + \vec{\pi}(t) V_i,
  \quad \frac{\dd \vec{\uppi}(t)}{\dd t} = \vec{\uppi}_i(t) Q,
  \quad \vec{s}_i(0) = \vec{0}, \quad \vec{\uppi}(0) = \vec{\uppi}_0
  \text,
\end{equation}
where $V_i = \partial Q(\vec{\uptheta}) / \partial \theta[i]$ is the
partial derivative of the generator
matrix~\citep{DBLP:conf/sigmetrics/RameshT93}. A similar initial value
problem can be derived for the sensitivity of $\vec{L}(t)$ and $Y(t)$.

To obtain the sensitivity $\vec{s}_i$ of the steady-state probability
vector $\vec{\uppi}$, the system of linear equations
\begin{equation}
  \label{eq:background:ctmc:sensitvity:s}
  \vec{s}_i Q = -\vec{\uppi} V_i, \quad \vec{s}_i \vec{1}^T = 0
\end{equation}
is solved~\citep{DBLP:conf/sigmetrics/BlakeRT88}.

Another type of sensitivity analysis considers \emph{unstructured}
small perturbations of the infinitesimal generator matrix $Q$ instead
of dependecies on parameters%
~\citep{funderlic1986sensitivity,ipsen1994uniform}. This latter,
unstructured analysis may be used to study the numerical stability and
conditioning of the solutions of the Markov chain.

\subsection{Time to first failure}
\label{ssec:background:mtff}

Computing the first time of a system failure (provided it was fully operational when it was started) has many applications in reliability engineering.

Let $D \subsetneq S$ be a set of \emph{failure states} of the \CTMC\ 
$X(t)$ and $U = S \setminus D$ be a set of operating states. We will
assume without loss of generality that $U = \{0, 1, \ldots, n_U - 1\}$
and $D = \{ n_U, n_U + 1, \ldots, n - 1 \}$.

The matrix
\begin{equation}
  Q_{UD} = \begin{pmatrix}
    Q_{UU} & \vec{q}_{UD}^\T \\
    \vec{0} & 0
  \end{pmatrix}
\end{equation}
is the infinitesimal generator of a \CTMC\ $X_{UD}(t)$ in which all
the failures states $D$ were merged into a single state $n_U$ and all
outgoing transitions from $D$ were removed. The matrix $Q_{UU}$ is the
$n_U \times n_U$ upper left submatrix of $Q$, while the vector
$\vec{q}_{UD} \in \RR^{n_U}$ is defined as
\begin{equation}
  q_{UD}[x] = \sum_{y \in D} q[x, y] \text.
\end{equation}

If the initial distribution $\vec{\uppi}_0$ is $0$ for all failure
states (i.e.~$\pi_0[x] = 0$ for all $x \in D$), the \emph{Time
  to First Failure}
\begin{equation}
  \TFF = \inf \{ t \ge 0 : X(t) \in D \} = \inf \{ t \ge 0 : X_{UD}(t)
  = n_U \}
\end{equation}
is \emph{phase-type distributed} with parameters
$(\vec{\pi}_{U}, Q_{UU})$~\citep{NEUT75}, where $\vec{\uppi}_U$ is the
vector containing the first $n_U$ elements of $\vec{\pi}_0$. In
particular, the \emph{Mean Time to First Failure} is computed as follows:
\begin{equation}
  \label{eq:background:mtff}
  \MTFF = \Ex[\TFF] = - \vec{\uppi}_U Q_{UU}^{-1} \vec{1}^\T \text.
\end{equation}

\noindent
The probability of a $D'$-mode failure ($D' \subset D$) is
\begin{equation}
  \label{eq:background:failure-mode}
  \Pr(X(\TFF_{+ 0}) = y) = - \vec{\uppi}_UQ_{UU}^{-1} \vec{q}_{UD'}^\T \text,
\end{equation}
where $\vec{q}_{UD'} \in \RR^{n_U}$,
$q_{UD'}[x] = \sum_{y \in D'} q[x, y]$ is the vector of transition
rates from operational states to failure states $D'$.

\section{Kronecker algebra}

\begin{dfn}
  The \emph{Kronecker product} of matrices
  $A \in \RR^{n_1 \times m_1}$ and $B \in \RR^{n_2 \times m_2}$ is the
  matrix $C = A \krtimes B \in \RR^{n_1 n_2 \times m_1 m_3}$, where
  \begin{equation}
    c[i_1 n_1 + i_2, j_1 m_1 + j_2] = a[i_1, j_1] b[i_2, j_2] \text.
  \end{equation}
\end{dfn}

Some properties of the Kroncker product are
\begin{enumerate}
\item Associativity:
  \begin{equation}
    A \krtimes (B \krtimes C) = (A \krtimes B) \krtimes C \text,
  \end{equation}
  which makes Kronecker products of the form $\loc{A}{0} \krtimes
  \loc{A}{1} \krtimes \cdots \krtimes \loc{A}{J - 1}$ well-defined.
\item Distributivity over matrix addition:
  \begin{equation}
    (A + B) \krtimes (C + D) = A \krtimes C + B \krtimes C + A
    \krtimes D + B \krtimes D \text,
  \end{equation}
\item Compatibility with ordinary matrix multiplication:
  \begin{gather}
    (AB) \krtimes (CD) = (A \krtimes C) (B \krtimes D) \text,
    \shortintertext{in particular,}
    A \krtimes B = (A \krtimes I_2) (I_1 \krtimes B)
  \end{gather}
  for identity matrices $I_1$ and $I_2$ with appropriate dimensions.
\end{enumerate}

We will occasionally employ multi-index notation to refer to elements
of Kronecker product matrices. For example, we will write
\begin{multline}
  b[\vec{x}, \vec{y}] = b[(\loc{x}{0}, \loc{x}{1}, \ldots, \loc{x}{J -
    1}), (\loc{y}{0}, \loc{y}{1}, \ldots, \loc{y}{J - 1})] = \\
  \loc{a}{0}[\loc{x}{0}, \loc{y}{0}] \loc{a}{1}[\loc{x}{1},
  \loc{y}{1}] \cdots \loc{a}{J - 1}[\loc{x}{J - 1}, \loc{y}{J - 1}]
  \text,
\end{multline}
where $\vec{x} = (\loc{x}{0}, \loc{x}{1}, \ldots, \loc{x}{J - 1})$,
$\vec{y} = (\loc{y}{0}, \loc{y}{1}, \ldots, \loc{y}{J - 1})$ and $B$
is the $J$-way Kronecker product
$\loc{A}{0} \krtimes \loc{A}{1} \krtimes \cdots \krtimes \loc{A}{J -
  1}$.

\begin{dfn}
  The \emph{Kronecker sum} of matrices
  $A \in \RR^{n_1 \times m_1}$ and $B \in \RR^{n_2 \times m_2}$ is the
  matrix $C = A \krplus B \in \RR^{n_1 n_2 \times m_1 m_3}$, where
  \begin{equation}
    C = A \krtimes I_2 + I_1 \krtimes B \text,
  \end{equation}
  where $I_1 \in \RR^{n_1 \times m_1}$ and $I_2 \in \RR^{n_2 \times
    m_2}$ are identity matrices.
\end{dfn}

\begin{example}
  Consider the matrices
  \begin{align}
    A &= \begin{pmatrix}
      1 & 2 \\
      3 & 4
    \end{pmatrix} \text,
    & B &= \begin{pmatrix}
      0 & 1 \\
      2 & 0
    \end{pmatrix} \text.
  \end{align}
  Their Kronecker product is
  \begin{equation}
    A \krtimes B = \begin{pmatrix}
      1 \cdot 0 & 1 \cdot 1 & 2 \cdot 0 & 2 \cdot 1 \\
      1 \cdot 2 & 1 \cdot 0 & 2 \cdot 2 & 2 \cdot 0 \\
      3 \cdot 0 & 3 \cdot 1 & 4 \cdot 0 & 4 \cdot 1 \\
      3 \cdot 2 & 3 \cdot 0 & 4 \cdot 2 & 4 \cdot 0
    \end{pmatrix} = \begin{pmatrix}
      0 & 1 & 0 & 2 \\
      2 & 0 & 4 & 0 \\
      0 & 3 & 0 & 4 \\
      6 & 0 & 8 & 0
    \end{pmatrix}\text,
  \end{equation}
  while their Kronecker sum is
  \begin{equation}
    A \krplus B = \begin{pmatrix}
      1 & 0 & 2 & 0 \\
      0 & 1 & 0 & 2 \\
      3 & 0 & 4 & 0 \\
      0 & 3 & 0 & 4
    \end{pmatrix} + \begin{pmatrix}
      0 & 1 & 0 & 0 \\
      2 & 0 & 0 & 0 \\
      0 & 0 & 0 & 1 \\
      0 & 0 & 2 & 0
    \end{pmatrix} = \begin{pmatrix}
      1 & 1 & 2 & 0 \\
      2 & 1 & 0 & 2 \\
      3 & 0 & 4 & 1 \\
      0 & 3 & 2 & 4
    \end{pmatrix}\text.
  \end{equation}
\end{example}

\section{Continuous-time stochastic automata networks}

\begin{dfn}
  A \emph{Continuous-time stochastic automata network} is a triple
  $\SAN = \bigl(E, \bigl( \loc{A}{j} \bigr)_{j = 0}^{J - 1},
  \lambda\bigr)$, where
  \begin{asparaitem}
  \item $E$ is a finite set of synchronizing \emph{events},
  \item $\loc{A}{j} = (\loc{S}{j}, \loc{x_0}{j}, \loc{E}{j},
    \loc{T}{j})$ is a \emph{stochastic automaton}, such that
    $\loc{E}{j} \subseteq E$ and $E = \bigcup_{j = 0}^{J - 1}
    \loc{E}{j}$,
  \item $\lambda: E \to \RRpos$ is an \emph{event rate function}.
  \end{asparaitem}
\end{dfn}

\begin{dfn}
  A \emph{stochastic automaton} is a $4$-tuple
  $A = (S, x_0, E, T)$, where
  \begin{asparaitem}
  \item $S$ is a finite set of \emph{states},
  \item $x_0 \in S$ is the \emph{initial state},
  \item $E$ is a finite set of synchronizing events,
  \item $T \subset E \times S \times S \times \RRpos$ is the
    \emph{local transition relation}, such that
    $(e, x, y, \mu) \in T$, written as $x \xrightarrow{e, \mu} y$,
    denotes a transition from $x$ to $y$ with rate $\mu$ synchronized
    on the event $e$. It is required that $x \xrightarrow{e, \mu} y, x
    \xrightarrow{e, \nu} y \implies \mu = \nu$, i.e. the rate of a
    transition is a (partial) function of its start and end states and
    synchronizing event.
  \end{asparaitem}
\end{dfn}

Parenthesised superscripts will be used to denote elements of
automatons of a \textls{SAN},
e.g.~$\loc{A}{j} = (\loc{S}{j}, \loc{x_0}{j}, \loc{E}{j}, \loc{T}{j})$
is the $j$th automaton of $\SAN$ with
$\lvert \loc{S}{j} \rvert = \loc{n}{j}$ states.

The set of \emph{potential states} of $\SAN$ is
\begin{equation}
  \PS = \loc{S}{0} \times \loc{S}{1} \times \cdots \times \loc{S}{J -
    1} \text,
\end{equation}
i.e. the Cartesian product of the state spaces of the automata. Thus,
\emph{global states} are vectors $\vec{x} = (\loc{x}{0}, \loc{x}{1},
\ldots, \loc{x}{J - 1})$. The initial global state is $\vec{x}_0 =
(\loc{x}{0}, \loc{x}{1}, \ldots, \loc{x}{J - 1})$.

\needspace{10ex}

The global state changes from $\vec{x} \in \PS$ to $\vec{y} \in \PS$
when the event $e \in E$ occurs,
\begin{equation}
  \label{eq:bakcground:san:transition}
  \vec{x} \tranto{e} \vec{y} \quad\Longleftrightarrow\quad
  \text{for all $0 \le j \le J - 1$ } \begin{cases}
    (e, \loc{x}{j}, \loc{y}{j}, \loc{\mu}{j}) \in \loc{T}{j}
    & \text{if $e \in \loc{E}{j}$,} \\
    \loc{x}{j} = \loc{y}{j} & \text{if $e \notin \loc{E}{j}$.}
  \end{cases}
\end{equation}

The \emph{support} of the event $e$ is the set of automata which
respond to it, $\supp e = \{ j : e \in \loc{E}{j} \}$. If $\supp e =
\{ j \}$, $e$ is \emph{local} to $\loc{A}{j}$.

The events local to $\loc{A}{j}$ are
$\loc{E_L}{j} = \{ e : \supp e = \{ j \}\}$. Events which affect other
automata are $\loc{E_S}{j} = \loc{E}{j} \setminus \loc{E_L}{j}$
synchronizing events of $\loc{A}{j}$. The set of all local events
is $E_L = \bigcup_{j = 0}^{J - 1} \loc{E_L}{j}$, while the set of all
synchronizing events is $E_S = \bigcup_{j = 0}^{J - 1} \loc{E_S}{j} =
E \setminus E_L$.

A state $\vec{y}$ is \emph{reachable} from the state $\vec{x}$
(written as $\vec{x} \reachto \vec{y}$) if there exists a sequence of
states and events for some finite $k$ such that
\begin{equation}
  \vec{x} = \vec{x}_1 \tranto{e_{i_1}} \vec{x}_2 \tranto{e_{i_2}}
  \vec{x}_3 \tranto{e_{i_3}} \cdots \tranto{e_{i_{k - 1}}} \vec{x}_{k
    - 1} \tranto{e_{i_k}} \vec{x}_k = \vec{y} \text.
\end{equation}

The state $\vec{y} \in \PS$ is in the \emph{reachable state space} of
$\SAN$ if $\vec{x}_0 \reachto \vec{y}$, hence the reachable state
space is
\begin{equation}
  \RS = \{ \vec{y} \in \PS : \vec{x}_0 \reachto \vec{y} \} \subseteq
  \PS \text.
\end{equation}

The term \emph{state space explosion} refers to the phenomenon that
even small models may have a very large number of states. For example,
if $\loc{n}{j} = c$ for all $0 \le j \le J - 1$, $\lvert \PS \rvert =
c^J$, hence $\RS$ may contain $O(c^J)$ elements.

We will assume a bijection
$\RS \leftrightarrow \{0, 1, \ldots, n - 1 \}$ between the reachable
state space and the natural numbers such that $\vec{x}_0 \mapsto 0$.
Moreover, we will assume a bijection
$\loc{S}{j} \leftrightarrow \{0, 1, \ldots, n_j - 1\}$ such that
$\loc{x_0}{j} \mapsto 0$. From now on, we will use natural number
state indices and abstract state vectors interchangeably.

\subsection{Stochastic automata networks as Markov chains}

We associate a Markov chain $X(t)$ with a \textls{SAN} as follows:
\begin{itemize}
\item The state space of the Markov chain is $S = \{0, 1, \ldots, n -
  1\}$, i.e.~the reachable states $\RS$ of $\SAN$ according to the
  assumed bijection.
\item The transition rate from $\vec{x}$ to $\vec{y}$ due to the event
  $e$ is $\lambda(e) \cdot \prod_{j \in \supp e} \loc{\mu}{j}$, where
  $\loc{x}{j} \xrightarrow{e, \loc{\mu}{j}} \loc{y}{j}$. Thus, the
  infinitesimal generator matrix $Q$ matrix of the $X(t)$ is formed
  by off-diagonal ($Q_O$) diagonal ($Q_D$) parts as
  \begin{gather}
    Q = Q_O + Q_D \text, \\
    q_O[x, y] = \begin{cases}
      0 & \text{if $x = y$,} \\
      \displaystyle \sum_{e \in E, \vec{x} \tranto{e} \vec{y}} \!\!
      \lambda(e) \cdot \prod_{j = 0\vphantom{[}}^{J - 1} \loc{\mu_e}{j} &
      \text{if $x \ne y$, where $\loc{x}{j}
        \xrightarrow{e, \loc{\mu_e}{j}} \loc{y}{j}$,}
    \end{cases} \\
    Q_D = - \diag \{ Q_O \vec{1}^\T \} \text. \\
  \end{gather}
\item The initial distribution concentrates all the probability mass
  at $\vec{x}_0$,
  \begin{equation}
    \vec{\pi}_0 = \begin{pmatrix}
      1 & 0 & 0 & \cdots & 0
    \end{pmatrix}\text,
  \end{equation}
  that is, $\pi_0[x] = \delta_{0,x}$.
\end{itemize}

The generator matrix requires $O(n^2)$ memory if a two-dimensional
dense array format is used.

Suppose that for each event $e$ and source state $\vec{x}$,
$\vec{x} \tranto{e} \vec{y}$ holds only for a number of different
target states $\vec{y}$ bounded from above by $k \in \NN$. Therefore,
each row of $Q$ contains up to $k \lvert E \rvert + 1$ nonzero
elements including the diagonal element. This means $Q$ requires
$O(n k \lvert E \rvert)$ memory if a sparse format is chosen, which is
preferable over dense arrays for larger models.

Unfortunately, both of these storage methods may be prohibitively
costly for large models due to state space explosion. In addition,
explicit enumeration of large $\RS$ may take an extreme amout of time.

\subsection{Kronecker generator matrices}

To alleviate the high memory requirements of $Q$, the Kronecker
decomposition for a \textls{SAN} with $J$ automata expresses the
infinitesimal generator matrix of the associated \CTMC\ in the form
\begin{equation}
  \label{eq:genstor:explicit:kronecker}
  Q = Q_O + Q_D, \quad Q_O = \bigkrplus_{j = 0}^{J - 1} \loc{Q_L}{j}
  + \sum_{e \in E_S} \lambda(e) \bigkrtimes_{j = 0}^{J - 1}
  \loc{Q_{e}}{j}, \quad Q_D = -\diag \{ Q_O \vec{1}^\T \} \text,
\end{equation}
where $Q_O$ and $Q_D$ are the off-diagonal and diagonal parts of
$Q$. The matrix
\begin{equation}
  \loc{Q_L}{j} = \sum_{e \in \loc{E_L}{j}} \lambda(e) \, \loc{Q_e}{j}
\end{equation}
is the \emph{local} transition matrix of the component $j$, while
the matrix
\begin{equation}
  \loc{Q_e}{j} \in \RR^{n_j \times n_j}, \quad
  \loc{q_e}{j}[\loc{x}{j},\loc{y}{j}] = \begin{cases}
    \mu & \text{if $\loc{x}{j} \xrightarrow{e, \mu} \loc{y}{j}$,} \\
    0 & \text{otherwise}
  \end{cases}
\end{equation}
describes the effects of the event $e$ on $\loc{A}{j}$. $\loc{Q_e}{j}$
has a nonzero element for every local state transition caused by
$e$. If $j \notin \supp e$, $\loc{Q_e}{j}$ is an $n_j \times n_j$
identity matrix.

The matrices $\loc{Q_L}{j}$ and $\loc{Q_e}{j}$ and the vector
$-Q_O \vec{1}^\T$ together are usually much smaller than the full
generator matrix $Q$ even when stored in a sparse matrix form. Hence
Kronecker decomposition may save a significant amount of storage at
the expense of some computation time.

Unfortunately, the Kronecker generator $Q$ is a
$n_0 n_1 \cdots n_{J - 1} \times n_0 n_1 \cdots n_{J - 1}$ matrix,
i.e.~in encodes the state transitions in the potential state space
$\PS$ instead of the reachable state space $\RS$.

\emph{Potential Kronecker methods}%
~\citep{DBLP:journals/informs/BuchholzCDK00} perform computations with
the $\lvert \PS \rvert \times \lvert \PS \rvert$ $Q$ matrix and
vectors of length $\lvert \PS \rvert$. In addition to increasing
storage requirements, this may lead to problems in some numerical
solution algorithms, because the \CTMC\ over $\PS$ is not neccessarily
irreducible even if it is irreducible over $\RS$.

In contrast, \emph{actual Kronecker methods}~%
\citep{DBLP:journals/tse/Kemper96,%
  DBLP:journals/informs/BuchholzCDK00,%
  DBLP:journals/fgcs/BenoitPS06} work with vectors of length
$\lvert \RS \rvert$. However, additional conversions must be performed
between the actual dense indexing of the vectors and the potential
sparse indexing of the $Q$ matrix, which leads to implementation
complexities and computational overhead.

A third approach, which we discuss in the next subsection, imposes a
hierarchical structure on $\RS$~%
\citep{DBLP:conf/cpe/BauseBK98,%
  DBLP:journals/sigmetrics/BuchholzK98,%
  DBLP:journals/tse/Buchholz99}.

\subsection{Block kronecker matrix composition}

A \emph{hierarchical decomposition} of the reachable state space expresses
$\RS$ as
\begin{equation}
  \RS = \bigcup_{\macro{\vec{x}} \in \Macro{\RS}} \,
  \bigtimes_{\vphantom{\Macro{\RS}}j = 0}^{J - 1}
  \, \loc{\RS}{j}_{\loc{\macro{x}}{j}}, \quad
  \loc{\RS}{j} = \bigcup_{\mathclap{\loc{\macro{x}}{j} \in \loc{\Macro{\RS}}{j}}}
  \,\, \loc{\RS}{j}_{\loc{\macro{x}}{j}} \text,
\end{equation}
where
$\Macro{\RS} = \{\macro{0}, \macro{1}_1, \ldots, \Macro{\macro{n} - 1}
\}$
a set of \emph{global macro states},
$\loc{\Macro{\RS}}{j} = \{\loc{\macro{0}}{j}, \loc{\macro{1}}{j},
\ldots, \loc{\Macro{\macro{n}_j - 1}}{j} \}$ is the set of \emph{local
macro states} of $\loc{A}{j}$, and $\loc{\RS}{j}_{x} = \{\loc{0}{j}_x,
\loc{1}{j}_x, \ldots, \loc{(n_{j, x} - 1)}{j}_x \}$ are the
\emph{local micro states} in the local macro state
$\loc{\macro{x}}{j}$. The product symbol denotes the composition of
local states into a global state vector.

The decomposition of the state space into global macro states allows
$Q$ to be expressed as a block matrix, where each matrix block is
expressed using Kronecker decomposition.

The matrices $\loc{Q_e}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]$
and $\loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}] \in
\RR^{n_{j,x} \times n_{n, y}}$ describe
the effects of a single event $e \in E$ and the aggregated effects of
local transitions on $\loc{A}{j}$ as its state changes from the local
macro state $\loc{\macro{x}}{j}$ to $\loc{\macro{y}}{j}$,
respectively. Formally,
\begin{gather}
  \loc{q_e}{j}[\loc{\macro{x}}{j},
  \loc{\macro{y}}{j}][\loc{a_x}{j}, \loc{b_y}{j}] = \begin{cases}
    \mu & \text{if $\loc{a_x}{j} \xrightarrow{e, \mu} \loc{b_y}{j}$,} \\
    0 & \text{otherwise,}
  \end{cases} \label{eq:genstor:explicit:block:tran-matrix}\\
  \loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{y}}{j}] = \sum_{e \in
    \loc{E_L}{j}} \lambda(e) \, \loc{Q_e}{j}[\loc{\macro{x}}{j},
  \loc{\macro{y}}{j}] \label{eq:genstor:explicit:block:local-matrix} \text.
\end{gather}
In the case $j \notin \supp e$, we define $\loc{Q_e}{j}[\loc{\macro{x}}{j},
\loc{\macro{y}}{j}]$ as an identity matrix if $\loc{\macro{x}}{j} =
\loc{\macro{y}}{j}$ and a zero matrix otherwise.

Let us call macro state pairs $(\macro{\vec{x}}, \macro{\vec{y}})$
\emph{single local macro state transitions} (slmst.) at $h$ if $\macro{\vec{x}}$
and $\macro{\vec{y}}$ differ only in a single index $h$
($\loc{\macro{x}}{h} \ne \loc{\macro{y}}{j}$).

The off-diagonal part $Q_O$ of $Q$ is written as a block matrix with
$\macro{n} \times \macro{n}$ blocks. A single block is expressed as
\begin{equation}
  \label{eq:genstor:explicit:block:block}
  Q_O[\macro{\vec{x}}, \macro{\vec{y}}] = \begin{cases}
    \begin{multlined}[c][7cm]
      \bigkrplus_{j = 0}^{J - 1}
      \loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]\\[-4.5ex]
      + \sum_{e \in E_S} \lambda(e) \bigkrtimes_{j = 0}^{J - 1}
      \loc{Q_e}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]
    \end{multlined}
    & \text{if $\macro{\vec{x}} = \macro{\vec{y}}$,} \\[6.5ex]
    \begin{multlined}[c][7cm]
      I_{N_1 \times N_1} \krtimes
      \loc{Q_L}{h}[\loc{\macro{x}}{h}, \loc{\macro{x}}{h}] \krtimes
      I_{N_2 \times N_2} \\[-1.5ex]
      + \sum_{e \in E_S} \lambda(e) \bigkrtimes_{j = 0}^{J - 1}
      \loc{Q_e}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]
    \end{multlined}
    & \text{if
      $(\macro{\vec{x}}, \macro{\vec{y}})$ slmst.~at $h$,} \\[5ex]
    \displaystyle \sum_{e \in E_S} \lambda(e) \bigkrtimes_{j = 0}^{J - 1}
      \loc{Q_e}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}] &
      \text{otherwise,}
  \end{cases}
\end{equation}
where $I_1 = \prod_{f = 0}^{h - 1} n_{h, \loc{x}{h}}$,
$I_2 = \prod_{f = h + 1}^{J - 1} n_{h, \loc{x}{h}}$. If
$\vec{x} = \vec{y}$, the matrix block describes transitions which
leave the global macro state unchanged, therefore any local transition
may fire. If $(\macro{\vec{x}}, \macro{\vec{y}})$ is slmst.~at $h$,
only local transitions on the component $h$ may cause the global state
transition, since no other local transition may affect
$\loc{A}{h}$. In every other case, only synchronizing transitions may
occur.

This expansion of block matrices is equivalent to
\vref{eq:genstor:explicit:kronecker} except the considerations to the
hierarchical structure of the state space.

The full $Q$ matrix is written as
\begin{equation}
  Q = Q_O + Q_D, \quad Q_D = -\diag\{ Q_O \vec{1}^\T \}
\end{equation}
as usual.
