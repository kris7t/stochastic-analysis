\chapter{Efficient generation and storage of continuous-time Markov chains}
\chaptermark{Efficient generation and storage of CTMCs}
\label{chap:genstor}

\section{Explicit methods}

\subsection{Explicit state space and matrix construction}

Explicit state space enumeration for Petri nets repeatedly applies the
firing rule \vref{eq:background:petri:fire} starting from the initial
marking $M_0$ until no new marking can be generated. At the end of the
enumeration of the finite state space, all reachable markings
$M_0 \reachto M$ are discovered. We implemented detection of already
encountered markings by hashing, while new markings are generated by
breath-first search.

\begin{algorithm}
  \KwIn{explicit state space $\RS$, transitions $T$, transition rate
    function $\Lambda$}
  \KwOut{generator matrix $Q$}
  \KwAllocate{$Q_O \in \RR^{\lvert \RS \rvert \times \lvert \RS
      \rvert}, \vec{d} \in \RR^{\lvert \RS \rvert}$}\;
  \ForEach{$y \in \RS, t \in R$}{
    \If{there is a state $x \in \RS$ such that $M_x \tranto{t} M_y$}{
      $q_D[x, y] \gets q_D[x, y] + \Lambda(t)$\;
    }
  }
  $\vec{d} \gets - Q_O \vec{1}^\T$\;
  \KwRet{$Q_O + \diag\{ \vec{d} \}$}\;
  \caption{Generator matrix construction from explicit state space.}
  \label{alg:genstor:explicit:matrix}
\end{algorithm}

Given the finite state space of size $n = \lvert \RS \rvert$ in an
explicit form along with a bijection between the markings an the
natural numbers $\{0, 1, \ldots, n - 1\}$, the generator matrix $Q$
can be directly created by \cref{alg:genstor:explicit:matrix}. The
algorithm stores the transition rate $\Lambda(t)$ in $Q$ for all pairs
of reachable markings $M_x \tranto{t} M_y$ and transitions $t \in T$.

The generator matrix requires $O(n^2)$ memory if a two-dimensional
dense array format is used. Because firing a transition can only take
the Petri net from a given marking $M_x$ to a single target marking
$M_y$ in the \textls{SPN} formalism, each column of $Q$ may contain up
to $\lvert T \rvert$ nonzero elements. Hence $Q$ requires $O(\lvert T
\rvert n)$ memory if a sparse format is chosen.

Unfortunately, both of these storage methods may be prohibitively
costly for large models due to state space explosion. In addition,
explicit enumeration of large $\RS$ may take an extreme amout of
time.

\subsection{Block Kronecker generator matrices}

\subsubsection{Kronecker generator matrices}

To alleviate the high memory requirements of $Q$, the Kronecker
decomposition for a superposed \textls{SPN} with $J$ components
expresses the infinitesimal generator matrix of the associated \CTMC\
in the form
\begin{equation}
  \label{eq:genstor:explicit:kronecker}
  Q = Q_O + Q_D, \quad Q_O = \bigkrplus_{j = 0}^{J - 1} \loc{Q_L}{j}
  + \sum_{t \in T_S} \Lambda(t) \bigkrtimes_{j = 0}^{J - 1}
  \loc{Q_{t}}{j}, \quad Q_D = -\diag \{ Q_O \vec{1}^\T \} \text,
\end{equation}
where $Q_O$ and $Q_D$ are the off-diagonal and diagonal parts of
$Q$. The matrix
\begin{equation}
  \loc{Q_L}{j} = \sum_{t \in \loc{T_L}{j}} \Lambda(t) \, \loc{Q_L}{j}
\end{equation}
is the \emph{local} transition matrix of the component $j$, while
the matrix
\begin{equation}
  \loc{Q_t}{j} \in \RR^{n_j \times n_j}, \quad
  \loc{q_t}{j}[\loc{x}{j},\loc{y}{j}] = \begin{cases}
    1 & \text{if $\loc{x}{j} \tranto{t} \loc{y}{j}$,} \\
    0 & \text{otherwise}
  \end{cases}
\end{equation}
describes the effects of the transition $t$ on
$\LN{j}$. $\loc{Q_t}{j}$ has a nonzero element for every local state
transition caused by $t$. If $j \notin \supp t$, $\loc{Q_t}{j}$ is
an $n_j \times n_j$ identity matrix.

It can be seen that
\begin{align}
  q_O[\vec{x}, \vec{y}]
  &= \sum_{\vphantom{\loc{T_L}{j}}j = 0}^{J - 1} \,\, \sum_{t \in
    \loc{T_L}{j}} \Lambda(t) \,
    \loc{q_t}{j}[\loc{x}{j}, \loc{y}{j}] \, + \sum_{t \in T_S} \Lambda(t)
    \prod_{\vphantom{T_S}j = 0}^{J - 1}
    \loc{q_t}{j}[\loc{x}{j}, \loc{y}{j}] \\
  &= \sum_{\vphantom{\loc{T_L}{j}}j = 0}^{J - 1} \,\,
    \sum_{\substack{\vphantom{\loc{T_L}{j}}t \in \loc{T_L}{j} \\
  \mathclap{\loc{x}{j} \tranto{t} \loc{y}{j}}}} \Lambda(t) \, +
  \sum_{\mathclap{\in T_S, \vec{x} \tranto{t} \vec{y}}} \Lambda(t)
  = \sum_{\mathclap{\vphantom{T_S}t \in T, \vec{x} \tranto{t}
  \vec{y}}} \Lambda(t) \text,
  \label{eq:genstor:explicit:block:qblock}
\end{align}
which is the same as \vref{eq:background:spn:q-d}. Indeed,
\cref{eq:genstor:explicit:kronecker} is a representation of the
infinitesimal generator matrix.

The matrices $\loc{Q_L}{j}$ and $\loc{Q_t}{j}$ and the vector
$-Q_O \vec{1}^\T$ together are usually much smaller than the full
generator matrix $Q$ even when stored in a sparse matrix form. Hence
Kronecker decomposition may save a significant amount of storage at
the expense of some computation time.

Unfortunately, the Kronecker generator $Q$ is a
$n_0 n_1 \cdots n_{J - 1} \times n_0 n_1 \cdots n_{J - 1}$ matrix,
i.e.~in encodes the state transitions in the potential state space
$\PS$ instead of the reachable state space $\RS$.

\emph{Potential Kronecker methods}%
~\citep{DBLP:journals/informs/BuchholzCDK00} perform computations with
the $\lvert \PS \rvert \times \lvert \PS \rvert$ $Q$ matrix and
vectors of length $\lvert \PS \rvert$. In addition to increasing
storage requirements, this may lead to problems in some numerical
solution algorithms, because the \CTMC\ over $\PS$ is not neccessarily
irreducible even if it is irreducible over $\RS$.

In contrast, \emph{actual Kronecker methods}~%
\citep{DBLP:journals/tse/Kemper96,%
  DBLP:journals/informs/BuchholzCDK00,%
  DBLP:journals/fgcs/BenoitPS06} work with vectors of length
$\lvert \RS \rvert$. However, additional conversions must be performed
between the actual dense indexing of the vectors and the potential
sparse indexing of the $Q$ matrix, which leads to implementation
complexities and computational overhead.

A third approach, which we discuss in the next subsection, imposes a
hierarchical structure on $\RS$~%
\citep{DBLP:conf/cpe/BauseBK98,%
  DBLP:journals/sigmetrics/BuchholzK98,%
  DBLP:journals/tse/Buchholz99}.

\subsubsection{Macro state construction}

The hierarchical structure of the reachable state space expresses
$\RS$ as
\begin{equation}
  \RS = \bigcup_{\macro{\vec{x}} \in \Macro{\RS}}
  \prod_{\vphantom{\Macro{\RS}}j = 0}^{J - 1}
  \, \loc{\RS}{j}_{\loc{\macro{x}}{j}}, \quad
  \loc{\RS}{j} = \bigcup_{\mathclap{\loc{\macro{x}}{j} \in \loc{\Macro{\RS}}{j}}}
  \,\, \loc{\RS}{j}_{\loc{\macro{x}}{j}} \text,
\end{equation}
where
$\Macro{\RS} = \{\macro{0}, \macro{1}_1, \ldots, \Macro{\macro{n} - 1}
\}$
a set of \emph{global macro states},
$\loc{\Macro{\RS}}{j} = \{\loc{\macro{0}}{j}, \loc{\macro{1}}{j},
\ldots, \loc{\Macro{\macro{n}_j - 1}}{j} \}$ is the set of \emph{local
macro states} of $\LN{j}$, and $\loc{\RS}{j}_{x} = \{\loc{0}{j}_x,
\loc{1}{j}_x, \ldots, \loc{(n_{j, x} - 1)}{j}_x \}$ are the
\emph{local micro states} in the local macro state
$\loc{\macro{x}}{j}$. The product symbol denotes the composition of
local markings, as in \vref{eq:background:sspn:concat}.

The local micro states form a partition
$\loc{\RS}{j} = \bigcup_{x \in \loc{\Macro{RS}}{j}} \loc{\RS}{j}_{x}$
of the state space of the $j$th \textls{SSPN} component.

Construction of macro states is performed as follows%
~\citep{DBLP:journals/tse/Buchholz99}:
\begin{enumerate}
\item The equivalence relation $\loc{\sim}{j}$ is defined over
  $\loc{\RS}{j}$ as
  \begin{equation}
    \label{eq:genstor:explicit:block:locsim}
    \loc{x}{j} \mathbin{\loc{\sim}{j}} \loc{y}{j}
    \quad\Longleftrightarrow\quad \{ \loc{\hat{\vec{z}}}{j} : \vec{x}
    \in \RS, \loc{z}{j} =
    \loc{x}{j} \} = \{ \loc{\hat{\vec{z}}}{j} : \vec{x} \in \RS, \loc{z}{j} = \loc{y}{j} \}
    \text,
  \end{equation}
  where
  $\loc{\hat{\vec{z}}}{j} = (\loc{z}{0}, \ldots, \loc{z}{j - 1},
  \loc{z}{j + 1}, \ldots, \loc{z}{J - 1})$,
  i.e.~two local states are equivalent if they are reachable in the
  same combinations of ambient local markings. Therefore, the relation
  \begin{equation}
    \vec{x} \sim \vec{y} \quad\Longleftrightarrow\quad \loc{x}{j}
    \mathbin{\loc{\sim}{j}} \loc{y}{j} \text{ for all $j = 0, 1,
      \ldots, J - 1$,}
  \end{equation}
  defined over $\PS$, has the property that whether
  $\vec{x} \sim \vec{y}$, either both $\vec{x}$ and $\vec{y}$ are
  reachable (global) markings, or neither are.
\item Reachable local macro states are the partitions of
  $\loc{\RS}{j}$ generated by $\loc{\sim}{j}$. A bijection
  $\loc{\Macro{\RS}}{j} \leftrightarrow \loc{\RS}{j} / {\loc{\sim}{j}}$
  is formed between the integers
  $0, 1, \ldots, \loc{\macro{n}}{j} - 1$ and the local state
  partitions for each component $\LN{j}$.
\item The set of potential macro states is
  \begin{equation}
    \Macro{\PS} = \prod_{j = 0}^{J - 1} \loc{\Macro{\RS}}{j}
    \supseteq \Macro{\RS}
  \end{equation}
  the Cartesian product of the local macro states. If macro state
  $\macro{x} \in \Macro{\PS}$ contains a reachable state, all
  associated (micro) states are reachable, because $\Macro{\PS}$ is
  the partition $\RS / {\sim}$ of $\RS$ generated by the relation
  $\sim$. Thus, $\Macro{\RS}$ is constructed by enumerating the
  reachable macro states in $\Macro{\PS}$. A bijection is formed
  between the reachable subset of $\Macro{\PS}$ and the integers
  $\macro{0}, \macro{1}, \ldots, \Macro{\macro{n} - 1}$.
\end{enumerate}

\begin{algorithm}
  \KwIn{Reachable state space $\RS$, reachable local state spaces
    $\loc{\RS}{j}$}
  \KwOut{Macro state space $\Macro{RS}$, local macro state spaces
    $\loc{\Macro{\RS}}{j}$}
  \KwAllocate{bit vector $\vec{b} \in \{0, 1\}^{n_0 n_1 \cdots n_{J -
        1}}$ initialized with zeroes}\;
  \ForEach{$\vec{x} \in \RS$}{
    \tcp{Fill $\vec{b}$ with ones corresponding to reachable states}
    $b[n_{J - 1} n_{J - 2} \cdots n_1 \loc{x}{0} + n_{J - 1} n_{J - 2}
    \cdots n_2 \loc{x}{1} + \cdots + n_{J - 1} \loc{x}{J - 2} +
    \loc{x}{J - 1}] \gets 1$\;
  }
  \For{$j \gets 0$ \KwTo $J - 1$}{
    Reshape $\vec{b}$ into matrix $B$ with $n_j$ columns\;
    Partition the columns of $B$ by componentwise equality
    \label{ln:genstor:explicit:block:macro:partition}\;
    \ForEach{subset $S$ of the partition $B/{=}$}{
      Create a new local macro state $\loc{\macro{y}}{j}$ in
      $\loc{\Macro{\RS}}{j}$\;
      Assign all local micro states $z \in S$ to $\loc{\macro{y}}{j}$\;
      Drop all columns of $B$ corresponding to $S$
      but a single representant of $\loc{\macro{y}}{j}$\;
    }
  }
  \ForEach{$\macro{\vec{x}} \in \loc{\RS}{0} \times \loc{\RS}{1}
    \times \cdots \times \loc{\RS}{J - 1}$}{
    \lIf{$b[\macro{\vec{x}}] = 1$}{
      Add $\macro{\vec{x}}$ to $\Macro{\RS}$ as a global macro state
    }
  }
  \KwRet{$\Macro{\RS}, \bigl\{\loc{\Macro{\RS}}{j}\bigr\}_{j = 0}^{J -
      1}$}\;
  \caption{Hiearchical decomposition of the reachable state space into
    macro states by \citet{DBLP:journals/tse/Buchholz99}.}
  \label{alg:genstor:explicit:block:macro}
\end{algorithm}

The pseudocode for this process is shown in
\cref{alg:genstor:explicit:block:macro}. The decomposition is
extremely memory demanding due to the allocation of the bit vector
$\vec{b}$ of length $\lvert \PS \rvert$.

In \citep{DBLP:journals/tse/Buchholz99}, sorting the columns of $B$
lexicographically was recommended to calculate the partition $B / {=}$
In our implementation, we insert the rows of $B$ into a bitwise trie
and detect duplicates instead, so that no mapping between the original
order and sorted ordering of columns needs to be maintained.

\begin{runningExample}
  The macro states of the \emph{RunningExample} \textls{SSPN} model
  (\vref{fig:background:sspn:sharedresource}) are obtained from its
  component state space
  (\vref{tab:background:sspn:sharedresource-states}) as follows:
  \begin{enumerate}
  \item The bit vector $\vec{b}$ is filled according to the reachable
    states $\RS$,
    \begin{equation}
      \begin{blockarray}{r@{\mkern15mu}*{18}{>{$\bgroup\small$}c<{$\egroup$}}@{\mkern12mu}l}
        & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 2 & 2 & 2 &
        2 & 2 & 2 & \\[-0.7ex]
        & 0 & 0 & 1 & 1 & 2 & 2 & 0 & 0 & 1 & 1 & 2 & 2 & 0 & 0 & 1 &
        1 & 2 & 2 & \\[-0.7ex]
        & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 &
        1 & 0 & 1 & \\[-0.5ex]
        \begin{block}{r@{\mkern15mu}(*{18}{c})@{\mkern12mu}l}
          \vec{b} = & 1 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 1 &
          0 & 1 & 0 & 1 & 0 & 0 & \text, \\
        \end{block}
      \end{blockarray}
    \end{equation}
    where the mixed indices in small type refer to the states of the
    local nets $\LN{0}$, $\LN{1}$ and $\LN{2}$.
  \item We reshape $\vec{b}$ into a matrix $B$ so that each column
    corresponds to a local state of the component $\LN{0}$,
    \begin{equation}
      \begin{blockarray}{r*{2}{@{\mkern5mu}>{$\bgroup\small$}c<{$\egroup$}}*{3}{>{$\bgroup\small$}c<{$\egroup$}}}
        & & & 0 & 1 & 2 \\[-0.5ex]
        \begin{block}{r*{2}{@{\mkern5mu}>{$\bgroup\small$}c<{$\egroup$}}(*{3}{c})}
          \multirow{6}{*}{$B =\,$} & 0 & 0 & 1 & 1 & 0 \\
          & 0 & 1 & 0 & 0 & 1 \\
          & 1 & 0 & 1 & 1 & 0 \\
          & 1 & 1 & 0 & 0 & 1 \\
          & 2 & 0 & 0 & 0 & 0 \\
          & 2 & 1 & 1 & 1 & 0 \\
        \end{block}
      \end{blockarray}
    \end{equation}
    in order to conclude that
    \begin{align}
      \loc{\Macro{\RS}}{0}_0
      &= \{ \loc{0}{0}_0 = \loc{M}{0}_0, \loc{1}{0}_0 = \loc{M}{0}_1 \},
      &\loc{\Macro{\RS}}{0}_1
      &= \{ \loc{0}{0}_1 = \loc{M}{0}_2 \}.
    \end{align}
  \item After removing all local states of $\LN{0}$ except
    representants of $\loc{\Macro{\RS}}{0}$, $\vec{b}$ is reshaped
    again
    \begin{equation}
      \begin{blockarray}{r*{2}{@{\mkern5mu}>{$\bgroup\small$}c<{$\egroup$}}*{3}{>{$\bgroup\small$}c<{$\egroup$}}}
        & & & 0 & 1 & 2 \\[-0.5ex]
        \begin{block}{r*{2}{@{\mkern5mu}>{$\bgroup\small$}c<{$\egroup$}}(*{3}{c})}
          \multirow{4}{*}{$B =\,$} & \macro{0} & 0 & 1 & 1 & 0 \\
          & \macro{0} & 1 & 0 & 0 & 1 \\
          & \macro{1} & 0 & 0 & 0 & 0 \\
          & \macro{1} & 1 & 1 & 1 & 0 \\
      \end{blockarray}
    \end{equation}
    to find that
    \begin{align}
      \loc{\Macro{\RS}}{1}_0
      &= \{ \loc{0}{1}_0 = \loc{M}{1}_0, \loc{1}{1}_0 = \loc{M}{1}_1 \},
      &\loc{\Macro{\RS}}{0}_1
      &= \{ \loc{0}{1}_1 = \loc{M}{1}_2 \}.
    \end{align}
  \item Finally, we reshape
    \begin{equation}
      \begin{blockarray}{r*{2}{@{\mkern5mu}>{$\bgroup\small$}c<{$\egroup$}}*{2}{>{$\bgroup\small$}c<{$\egroup$}}}
        & & & 0 & 1\\[-0.5ex]
        \begin{block}{r*{2}{@{\mkern5mu}>{$\bgroup\small$}c<{$\egroup$}}(*{2}{c})}
          \multirow{4}{*}{$B =\,$} & \macro{0} & \macro{0} & 1 & 0 \\
          & \macro{0} & \macro{1} & 0 & 1 \\
          & \macro{1} & \macro{0} & 0 & 1 \\
          & \macro{1} & \macro{1} & 0 & 0 \\
      \end{blockarray}
    \end{equation}
    and conclude
    \begin{align}
      \loc{\Macro{\RS}}{2}_0
      &= \{ \loc{0}{2}_0 = \loc{M}{2}_0\},
      &\loc{\Macro{\RS}}{2}_1
      &= \{ \loc{0}{2}_1 = \loc{M}{2}_1 \}.
    \end{align}
  \item Unfolding the matrix $B$
    \begin{equation}
      \begin{blockarray}{r@{\mkern15mu}*{8}{>{$\bgroup\small$}c<{$\egroup$}}}
        & \macro{0} & \macro{0} & \macro{0} & \macro{0} & \macro{1} &
        \macro{1} & \macro{1} & \macro{1} \\[-0.5ex]
        & \macro{0} & \macro{0} & \macro{1} & \macro{1} & \macro{0} &
        \macro{0} & \macro{1} & \macro{1} \\[-0.5ex]
        & \macro{0} & \macro{1} & \macro{0} & \macro{1} & \macro{0} &
        \macro{1} & \macro{0} & \macro{1} \\[-0.5ex]
        \begin{block}{r@{\mkern15mu}(*{8}{c})}
          \vec{b} = & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\
        \end{block}
      \end{blockarray}
    \end{equation}
    shows that the reachable global macro states are
    \begin{equation}
      \Macro{\RS} = \{ \macro{0} = ( \loc{\macro{0}}{0},
      \loc{\macro{0}}{1}, \loc{\macro{0}}{2} ),
      \macro{1} = ( \loc{\macro{0}}{0},
      \loc{\macro{1}}{1}, \loc{\macro{1}}{2} ),
      \macro{2} = ( \loc{\macro{1}}{0},
      \loc{\macro{0}}{1}, \loc{\macro{1}}{2} ) \} \text,
    \end{equation}
    where $\macro{0}$ corresponds to the free state of the resource,
    while in $\macro{1}$ and $\macro{2}$, the clients $\LN{1}$ and
    $\LN{0}$ are using the resource, respectively.
  \end{enumerate}
\end{runningExample}

\subsubsection{Block kronecker matrix composition}

The \emph{hierarchical} or \emph{block} Kronecker form of $Q$
expresses the infinitesimal generator of the \CTMC\ over the reachable
state space by the means of macro state decomposition.

The matrices $\loc{Q_t}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]$
and $\loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}] \in
\RR^{n_{j,x} \times n_{n, y}}$ describe
the effects of a single transition $t \in T$ and the aggregated effects of
local transitions on $\LN{j}$ as its state changes from the local
macro state $\loc{\macro{x}}{j}$ to $\loc{\macro{y}}{j}$,
respectively. Formally,
\begin{gather}
  \loc{q_t}{j}[\loc{\macro{x}}{j},
  \loc{\macro{y}}{j}][\loc{a_x}{j}, \loc{b_y}{j}] = \begin{cases}
    1 & \text{if $\loc{a_x}{j} \tranto{t} \loc{b_y}{j}$,} \\
    0 & \text{otherwise,}
  \end{cases} \label{eq:genstor:explicit:block:tran-matrix}\\
  \loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{y}}{j}] = \sum_{t \in
    \loc{T_L}{j}} \Lambda(t) \, \loc{Q_t}{j}[\loc{\macro{x}}{j},
  \loc{\macro{y}}{j}] \label{eq:genstor:explicit:block:local-matrix} \text.
\end{gather}
In the case $j \notin \supp t$, we define $\loc{Q_t}{j}[\loc{\macro{x}}{j},
\loc{\macro{y}}{j}]$ as an identity matrix if $\loc{\macro{x}}{j} =
\loc{\macro{y}}{j}$ and a zero matrix otherwise.

Let us call macro state pairs $(\macro{\vec{x}}, \macro{\vec{y}})$
\emph{single local macro state transitions} (slmst.) at $h$ if $\macro{\vec{x}}$
and $\macro{\vec{y}}$ differ only in a single index $h$
($\loc{\macro{x}}{h} \ne \loc{\macro{y}}{j}$).

The off-diagonal part $Q_O$ of $Q$ is written as a block matrix with
$\macro{n} \times \macro{n}$ blocks. A single block is expressed as
\begin{equation}
  \label{eq:genstor:explicit:block:block}
  Q_O[\macro{\vec{x}}, \macro{\vec{y}}] = \begin{cases}
    \begin{multlined}[c][7cm]
      \bigkrplus_{j = 0}^{J - 1}
      \loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]\\[-4.5ex]
      + \sum_{t \in T_S} \Lambda(t) \bigkrtimes_{j = 0}^{J - 1}
      \loc{Q_t}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]
    \end{multlined}
    & \text{if $\macro{\vec{x}} = \macro{\vec{y}}$,} \\[6.5ex]
    \begin{multlined}[c][7cm]
      I_{N_1 \times N_1} \krtimes
      \loc{Q_L}{h}[\loc{\macro{x}}{h}, \loc{\macro{x}}{h}] \krtimes
      I_{N_12\times N_2} \\[-1.5ex]
      + \sum_{t \in T_S} \Lambda(t) \bigkrtimes_{j = 0}^{J - 1}
      \loc{Q_t}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]
    \end{multlined}
    & \text{if
      $(\macro{\vec{x}}, \macro{\vec{y}})$ is slmst.~at $h$,} \\[5ex]
    \displaystyle \sum_{t \in T_S} \Lambda(t) \bigkrtimes_{j = 0}^{J - 1}
      \loc{Q_t}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}] &
      \text{otherwise,}
  \end{cases}
\end{equation}
where $I_1 = \prod_{f = 0}^{h - 1} n_{h, \loc{x}{h}}$, $I_2 = \prod_{f
  = h + 1}^{J - 1} n_{h, \loc{x}{h}}$. If $\vec{x} = \vec{y}$, the
matrix block describes transitions which leave the global macro state
unchanged, therefore any local transition may fire. If
$(\macro{\vec{x}}, \macro{\vec{y}})$ is slmst.~at $h$, only local
transitions on the component $h$ may cause the global state
transition, since no other local transition may affect $\LN{h}$. In
every other case, only synchronizing transitions may occur.

This expansion of block matrices is equivalent to
\vref{eq:genstor:explicit:kronecker} except the considerations to the
hierarchical structure of the state space.

The full $Q$ matrix is written as
\begin{equation}
  Q = Q_O + Q_D, \quad Q_D = -\diag\{ Q_O \vec{1}^\T \}
\end{equation}
as usual.

\begin{algorithm}
  \KwIn{State spaces $\loc{\Macro{\RS}}{j} \loc{\RS_x}{j}$,
    transitions $T$, transition rates $\Lambda$}
  \KwOut{Transition matrices $\loc{Q_t}{j}, \loc{Q_L}{j}$}
  \For{$j \gets 0$ \KwTo $J - 1$}{
    \ForEach{$(\loc{\macro{x}}{j}, \loc{\macro{y}}{j}) \in
      \loc{\Macro{\RS}}{j} \times \loc{\Macro{\RS}}{j}$}{%
      \uIf{$j \in \supp t$}{
        \KwAllocate{$\loc{Q_t}{j}[\loc{\macro{x}}{j},
          \loc{\macro{y}}{j}] \in \RR^{n_{j,x} \times n_{n,y}}$}\;
        Fill in $\loc{Q_t}{j}[\loc{\macro{x}}{j},
          \loc{\macro{y}}{j}]$ according to
          \vref{eq:genstor:explicit:block:tran-matrix}
      }
      \lElseIf{$\loc{\macro{x}}{j} = \loc{\macro{y}}{j}$}{
        $\loc{Q_t}{j}[\loc{\macro{x}}{j}, \loc{\macro{y}}{j}] \gets
        I_{n_{j,x} \times n_{j,y}}$
      }
      \lElse{$\loc{Q_t}{j}[\loc{\macro{x}}{j}, \loc{\macro{y}}{j}]
        \gets 0_{n_{j,x} \times n_{j,y}}$}
    }
    \KwAllocate{$\loc{Q_L}{j}[\loc{\macro{x}}{j},
      \loc{\macro{y}}{j}] \in \RR^{n_{j,x} \times n_{n,y}}$}\;
    \ForEach{$t \in \loc{T_L}{j}$}{
      $\loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{y}}{j}] \gets
      \loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{y}}{j}] +
      \Lambda(t) \, \loc{Q_t}{j}[\loc{\macro{x}}{j},
      \loc{\macro{y}}{j}]$
    }
  }
  \caption{Transition matrix construction for block Kronecker
    matrices}
  \label{alg:genstor:explicit:block:tranmatrix}
\end{algorithm}

\begin{algorithm}
  \KwIn{State spaces $\Macro{\RS},
    \loc{\Macro{\RS}}{j} \loc{\RS_x}{j}$, transitions $T$, transition
    rates $\Lambda$,\\matrices $\loc{Q_t}{j}, \loc{Q_L}{j}$}
  \KwOut{Infinitesimal generator $Q$}
  \KwAllocate{block matrix $Q$ with $\macro{n} \times \macro{n}$
    blocks}\;
  \ForEach{$(\macro{\vec{x}}, \macro{\vec{y}}) \in \Macro{\RS} \times
    \Macro{\RS}$}{
    Initialize $Q[\macro{\vec{x}}, \macro{\vec{y}}]$ as a linear
    combination of matrices\;
    \uIf{$\macro{\vec{x}} = \macro{\vec{y}}$}{
      \For{$j \gets 0$ \KwTo $J - 1$}{
        \If{$\loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{y}}{j}] \ne 0$}{
          $I_1 \gets I_{\prod_{f = 0}^{j - 1} n_{f, \loc{x}{f}} \times
            \prod_{h = 0}^{j - 1} n_{f, \loc{x}{f}}}, \quad
          I_2 \gets\text I_{\prod_{g = j + 1}^{J - 1} n_{f, \loc{x}{f}} \times
            \prod_{f = j + 1}^{J - 1} n_{f, \loc{x}{f}}}$\;
          $Q[\macro{\vec{x}}, \macro{\vec{x}}] \gets Q[\macro{\vec{x}},
          \macro{\vec{x}}] + I_1 \krtimes
          \loc{Q_L}{j}[\loc{\macro{x}}{j}, \loc{\macro{x}}{j}]
          \krtimes I_2$\;
        }
      }
    }
    \ElseIf{$(\macro{\vec{x}}, \macro{\vec{y}})$ is a slmst.~at $h$}{
      $I_1 \gets I_{\prod_{f = 0}^{h - 1} n_{f, \loc{x}{f}} \times
        \prod_{h = 0}^{h - 1} n_{f, \loc{x}{f}}}, \quad
      I_2 \gets\text I_{\prod_{f = f + 1}^{J - 1} n_{f, \loc{x}{f}} \times
        \prod_{f = h + 1}^{J - 1} n_{f, \loc{x}{f}}}$\;
      $Q[\macro{\vec{x}}, \macro{\vec{x}}] \gets Q[\macro{\vec{x}},
      \macro{\vec{x}}] + I_1 \krtimes
      \loc{Q_L}{h}[\loc{\macro{x}}{h}, \loc{\macro{x}}{h}]
      \krtimes I_2$\;
    }
    \ForEach{$t \in T_S$}{
      Initialize $B$ as an empty Kronecker product\;
      $\textit{zeroProduct} \gets \KwFalse$\;
      \For{$j \gets 0$ \KwTo $J - 1$}{
        \uIf{$\loc{Q}{j}[\vec{x}, \vec{y}] = 0$}{
          $\textit{zeroProduct} \gets \KwTrue$\;
          \KwSty{break}\;
        }
        \uElseIf{$\loc{Q}{j}[\vec{x}, \vec{y}]$ is an identity
          matrix}{
          \uIf{the last term of $B$ is an indentity matrix $I_{N, N}$}{
            Enlarge the last term of $B$ to $I_{N n_{j,x} \times N
              n_{j,y}}$
            \label{ln:genstor:explicit:block:construction:extend}\;
          }
          \lElse{
            $B \gets B \krtimes \loc{Q}{j}[\vec{x}, \vec{y}]$
          }
        }
      }
      \lIf{$\neg \textit{zeroProduct}$}{
        $Q[\vec{x}, \vec{y}] \gets Q[\vec{x}, \vec{y}] + \Lambda(t)\,
        B$ \label{ln:genstor:explicit:block:construction:discard}
      }
    }
  }
  \KwAllocate{block vector $\vec{d}$ with $\macro{n}$ blocks}\;
  $\vec{d} \gets -Q \vec{1}^\T$\;
  \lForEach{$\macro{x} \in \Macro{\RS}$}{
    $Q[\macro{x}, \macro{x}] \gets Q[\macro{x}, \macro{x}] + \diag
    \{ \vec{d}[\macro{x}] \}$
    \label{ln:genstor:explicit:block:construction:diagonal}
  }
  \KwRet{$Q$}
  \caption{Block Kronecker matrix construction.}
  \label{alg:genstor:explicit:block:construction}
\end{algorithm}

\Vref{alg:genstor:explicit:block:tranmatrix} shows the construction of
the local transition matrices according to
\cref{eq:genstor:explicit:block:tran-matrix,%
eq:genstor:explicit:block:local-matrix}.

The construction of the block matrix $Q$ is shown in
\vref{alg:genstor:explicit:block:construction}. We optimized the formulation from
\cref{eq:genstor:explicit:block:qblock} in several ways:
\begin{itemize}
\item If a Kronecker product contains a $0$ matrix term, it is itself
  zero, therefore, such products are discarded in line%
  ~\ref{ln:genstor:explicit:block:construction:discard}.
\item For identity matrices $I_{N \times N} \krtimes I_{n \times n}$
  holds. This is exploited in line%
  ~\ref{ln:genstor:explicit:block:construction:extend} to reduce the
  number of terms in the Kronecker producs.
\item Instead of constructing $Q_O$ and $Q_D$ separately, the diagonal
  elements are added to the blocks of $Q$ along its diagonal in line%
  ~\ref{ln:genstor:explicit:block:construction:diagonal}.
\end{itemize}

\section{Symbolic methods}

\subsection{Multivalued decision diagrams}

Multivalued decision diagrams (\textls{MDDs})~\citep{Ciardo:2006}
provide a compact, graph-based representation for functions of the
form $\NN^J \to \{0, 1\}$.

\begin{dfn}
  A quasi-reduced ordered \emph{multivalued decision diagram}
  (\textls{MDD}) encoding the function
  $f(\loc{x}{0}, \loc{x}{1}, \ldots, \loc{x}{J - 1}) \in \{0, 1\}$
  (where the domain of each variable $\loc{x}{j}$ is
  $\loc{D}{j} = \{0, 1, \ldots, n_j - 1\}$) is a tuple
  $\MDD = (V, \ddnode{r}, \ddnode{0}, \ddnode{1}, \mddLevel,
  \mddChildren)$, where
  \begin{asparaitem}
  \item $V = \bigcup_{i = 0}^{J} V_i$ is a finite set of \emph{nodes},
    where $V_0 = \{ \ddnode{0}, \ddnode{1} \}$ are the \emph{terminal
      nodes}, the rest of the nodes $V_N = V \setminus V_0$ are
    \emph{nonterminal nodes};
  \item $\mddLevel : V \to \{0, 1, \ldots, J\}$ assigns nonnegative
    \emph{level numbers} to each node
    ($V_i = \{\ddnode{v} \in V : \mddLevel(\ddnode{v}) = i \}$);
  \item $\ddnode{v} \in V_J$ is the \emph{root node};
  \item $\ddnode{0}, \ddnode{1} \in V_0$ are the \emph{zero} and
    \emph{one terminal nodes};
  \item $\mddChildren: \bigl( \bigcup_{i = 1}^J V_i \times \loc{D}{i
      - 1} \bigr) \to V$
    is a function defining edges between nodes labeled by the items of
    the domains, such that either
    $\mddChildren(\ddnode{v}, x) = \ddnode{0}$ or
    $\mddLevel(\mddChildren(\ddnode{v}, x)) = \mddLevel(\ddnode{v}) - 1$ for
    all $\ddnode{v} \in V$, $x \in \loc{D}{\mddLevel(\ddnode{v}) - 1}$,
  \item if $\ddnode{n}, \ddnode{m} \in V_j, j > 0$ then the subgraphs
    formed by the nodes reachable from $\ddnode{n}$ and $\ddnode{m}$
    are either non-isomorphic, or $\ddnode{n} = \ddnode{m}$.
  \end{asparaitem}
\end{dfn}

We remark that due to the presence of the terminal level $V_0$ the
indexing of the levels and the domains is shifted, i.e.~the level
$V_i$ corresponds to the domain $\loc{D}{i - 1}$.

According to the semantics of \textls{MDDs}, $f(\vec{x}) = 1$ if the
node $\ddnode{1}$ is reachable from $\ddnode{r}$ through the edges
labeled with $\loc{x}{0}, \loc{x}{1}, \ldots, \loc{x}{J - 1}$,
\begin{multline}
  f(\loc{x}{0}, \loc{x}{1}, \ldots, \loc{x}{J - 1}) = 1
  \quad\Longleftrightarrow\\
  \mddChildren(\mddChildren(\ldots \mddChildren(\ddnode{r}, \loc{x}{J
    - 1}) \ldots, \loc{x}{1}), \loc{x}{0}) = \ddnode{1} \text.
\end{multline}

\begin{dfn}
  A quasi-reduced ordered \emph{edge-valued multivalued decision
    diagram} (\textls{EDD}) \citep{DBLP:conf/nfm/RouxS10} encoding the
  function $g(\loc{x}{0}, \loc{x}{1}, \ldots, \loc{x}{J - 1}) \in \NN$
  is a tuple
  $\EDD = (V, \ddnode{r}, \ddnode{0}, \ddnode{1}, \mddLevel,
  \mddChildren, \eddLabel)$, where
  \begin{asparaitem}
  \item $\MDD = (V, \ddnode{r}, \ddnode{0}, \ddnode{1}, \mddLevel,
    \mddChildren)$ is a quasi-reduced ordered \textls{MDD},
  \item $\eddLabel: \bigl( \bigcup_{i = 1}^J V_i \times \loc{D}{i
      - 1} \bigr) \to \NN$ is an edge label function.
  \end{asparaitem}
\end{dfn}

According to the semantics of \textls{EDDs}, the function $g$ is
evaluated as
\begin{equation}
  g(\vec{x}) = \begin{cases}
    \text{undefined}
    & \text{if $f(\vec{x}) = 0$,} \\
    \sum_{j = 0}^{J - 1} \eddLabel(\loc{\ddnode{n}}{j}, \loc{x}{j})
    & \text{if $f(\vec{x}) = 1$,}
  \end{cases}
\end{equation}
where $f$ is the function associated with the underlying \textls{MDD}
and $\loc{\ddnode{n}}{j}$ are the nodes along the path to
$\ddnode{1}$, i.e.~
\begin{equation}
  \loc{\ddnode{n}}{J - 1} = \ddnode{r}, \quad \loc{\ddnode{n}}{j} =
  \mddChildren(\loc{\ddnode{n}}{j + 1}, \loc{x}{j + 1}) \text.
\end{equation}

\subsection{Symbolic state spaces}

Symbolic techniques involving \textls{MDDs} can efficiently store
large reachable state spaces of superposed Petri nets. Reachable
states $x \in \RS$ are associated with state codings $\vec{x} =
(\loc{x}{0}, \loc{x}{1}, \ldots, \loc{x}{J - 1})$. The function $f:
\PS \to \{0, 1\}$ can be stored as an \textls{MDD} where $f(\vec{x}) =
1$ if and only if $x \in \RS$. The domains of the \textls{MDD} are the
local state spaces $\loc{D}{j} = \loc{\RS}{j}$.

Similarly, \textls{EDDs} can efficiently store the mapping between
symbolic state encodings $\vec{x}$ and reachable state indices $x \in
\RS = \{0, 1, \ldots, n - 1\}$ as the function $g(\vec{x}) = x$. This
mapping is used to refer to elements of state probability vectors
$\vec{\uppi}$ and the sparse generator matrix $Q$ when these objects
are created and accessed.

\begin{figure}
  \centering
  \begin{tikzpicture}[
    ddnode/.style={
      draw,tdk highlight,
      rectangle split,
      rectangle split parts=#1,
      rectangle split horizontal,
      inner sep=5pt
    },
    terminal/.style={
      draw,circle,tdk highlight
    }
    ]

    \matrix [row sep=1.2cm,column sep=1cm,node distance=1cm] {
      \node {$V_3:$};
      & \node [ddnode=2] (x00) {0\nodepart{two}1}; \\
      \node {$V_2:$};
      & \node [ddnode=3] (x10) {0\nodepart{two}1\nodepart{three}2};
      & \node [ddnode=3] (x11) {0\nodepart{two}1\nodepart{three}2}; \\
      \node {$V_1:$};
      & \node [ddnode=3] (x20) {0\nodepart{two}1\nodepart{three}2};
      & \node [ddnode=3] (x21) {0\nodepart{two}1\nodepart{three}2}; \\
      \node {$V_0:$};
      & \node [terminal] (t0) {$\ddnode{0}$};
      & \node [terminal] (t1) {$\ddnode{1}$}; \\
    };

    \begin{scope}[
      every edge/.append style={-{Latex}},
      every node/.append style={above}
      ]
      \draw (x00.one south) edge node [right] {0} (x10);
      \draw (x00.two south) edge node [above] {4} (x11);
      \draw (x10.one south) edge node [left] {0} (x20);
      \draw (x10.two south) edge node [right] {2} (x20);
      \draw (x11.one south) edge node [left,yshift=-5pt,xshift=2pt] {0} (x21);
      \draw (x11.two south) edge node [right] {1} (x21);
      \draw (x11.three south) edge node [left,yshift=5pt] {2} (x20);
      \draw (x20.one south) edge node [below,xshift=-5pt] {0} (t1);
      \draw (x20.two south) edge node [xshift=5pt] {1} (t1);
      \draw (x21.three south) edge node [right] {0} (t1);
    \end{scope}
  \end{tikzpicture}
  \caption{\textls{EDD} state space mapping for the
    \emph{SharedResource} \textls{SSPN}.}
  \label{fig:genstor:symbolic:edd-example}
\end{figure}

\begin{runningExample}
  \Cref{fig:genstor:symbolic:edd-example} shows the state space of the
  \emph{SharedResource} model encoded as an \textls{EDD}. The edge
  labels express the lexicographic mapping of symbolic state codes
  $\vec{x}$ to state indices $\vec{x}$. Edges to the terminal zero
  node $\ddnode{0}$ were omitted for the sake of clarity.
\end{runningExample}

Some iteration strategies for \textls{MDD} state space exploration are
\emph{breath-first search} and \emph{saturation}%
~\citep{Ciardo:2006}. We use the implementation of saturation from the
\textls{Petridotnet} framework~\citep{TDK2010_Darvas,Petridotnet}.

\begin{algorithm}
  \KwIn{node for target state $\ddnode{t}$, node for
    source state $\ddnode{s}$, target state offset $y$, source state
    offset $y$, transition $t$, transition rate $\lambda$,
    matrix $Q_O$}
  \eIf{$\mddLevel(\ddnode{t}) = 0$}{
    \lIf{$\ddnode{t} = \ddnode{1} \land \ddnode{s} = \ddnode{1}$}{%
      $q_O[x, y] \gets q_O[x, y] + \lambda$}
  }{
    $j \gets \mddLevel(\ddnode{t}) - 1$\;
    \ForEach{$\loc{y}{j} \in \loc{RS}{j}$}{
      \lIf{$\mddChildren(\ddnode{t}, \loc{y}{j}) = \ddnode{0}$}{%
        \KwSty{return}
      }
      Find $\loc{x}{j}$ such that $\loc{x}{j} \tranto{t} \loc{y}{j}$\;
      \lIf{$\mddChildren(\ddnode{s}, \loc{x}{j}) = \ddnode{0}$}{%
        \KwSty{return}
      }
      $\textsc{FillIn}(\mddChildren(\ddnode{t}, \loc{y}{j}),
      \mddChildren(\ddnode{s}, \loc{x}{j}),$\\
      $\hphantom{\textsc{FillIn}(}y + \eddLabel(\ddnode{t},
      \loc{y}{j}), x + \eddLabel(\ddnode{t}, \loc{x}{j}), t, \lambda,
      Q_O)$\;
    }
  }
  \caption{\textsc{FillIn} procedure for matrix construction from
    \textls{EDD} state space.}
  \label{alg:genstor:symbolic:fillin}
\end{algorithm}

\begin{algorithm}
  \KwIn{state space \textls{MDD} root $\ddnode{r}$, state space size
    $n$, transitions $T$, transition rate function $\Lambda$}
  \KwOut{generator matrix $Q \in \RR^{n \times n}$}
  \KwAllocate{$Q_O \in \RR^{n \times n}$}\;
  \ForEach{$t \in T$}{
    $\textsc{FillIn}(\ddnode{r}, \ddnode{r}, 0, 0, t, \Lambda(t), Q_O)$\;
  }
  $\vec{d} \gets -Q_O \vec{1}^\T$\;
  \KwRet{$Q_O + \diag\{ \vec{d} \}$}\;
  \caption{Sparse matric construction from \textls{EDD} state space.}
  \label{alg:genstor:symbolic:sparse}
\end{algorithm}

\Vref{alg:genstor:symbolic:fillin,alg:genstor:symbolic:sparse}
illustrate the construction of a generator matrix based on the state
space encoded as \textls{EDDs}. The procedure \textsc{FillIn} descends
the \textls{EDD} following a path for the target and the source
state simulatenously. The edge labels, represeting state indices, are
summed on both paths. If a transition $\vec{x} \tranto{t} \vec{y}$ is
found, the matrix element $q_O[x, y]$ corresponding to the summed
indices in increated by the transition rate
$\Lambda(t)$. \Cref{alg:genstor:symbolic:sparse} repeats
\textsc{FillIn} for all transitions.

\subsection{Symbolic hierarchical state space decomposition}

The memory requirements and runtime of
\vref{alg:genstor:explicit:block:macro} may be significantly improved
by the use of symbolic state space storage instead of a bit vector.

To symbolically partition the local states $\loc{\RS}{j}$ into macro
states $\loc{\Macro{\RS}}{j}$, we will use the following notations of above and
below substates from \citet{ciardo2001saturation}:

\begin{dfn}
  The set of \emph{above} substates coded by the node $\ddnode{n}$ is
  \begin{gather}
    \mddAbove(\ddnode{n}) \subseteq \{ (\loc{x}{j + 1}, \loc{x}{j +
      2}, \ldots, \loc{x}{J - 1}) \in \loc{\RS}{j + 1} \times
    \loc{\RS}{j +
      2} \times \cdots \times \loc{\RS}{J - 1} \} \text, \\
    \intertext{such that}
    \vec{x} \in \mddAbove(\ddnode{n})
    \quad\Longleftrightarrow\quad \mddChildren(\mddChildren(\ldots
    \mddChildren(\ddnode{r}, \loc{x}{J - 1}) \ldots ,\loc{x}{j + 2}),
    \loc{x}{j + 1}) = \ddnode{n}
  \end{gather}
  and $j = \mddLevel(\ddnode{n}) - 1$, i.e.~$\mddAbove(\ddnode{n})$ is
  the set of all paths in the \textls{MDD} leading from $\ddnode{r}$
  to $\ddnode{n}$.
\end{dfn}

\begin{dfn}
  The set of \emph{below} substates coded by the node $\ddnode{n}$ is
  \begin{gather}
    \mddBelow(\ddnode{n}) \subseteq \{ (\loc{x}{0}, \loc{x}{1},
    \ldots, \loc{x}{j}) \in \loc{\RS}{0} \times
    \loc{\RS}{1} \times \cdots \times \loc{\RS}{j} \} \text, \\
    \intertext{such that}
    \vec{x} \in \mddBelow(\ddnode{n})
    \quad\Longleftrightarrow\quad \mddChildren(\mddChildren(\ldots
    \mddChildren(\ddnode{n}, \loc{x}{j}) \ldots ,\loc{x}{1}),
    \loc{x}{0}) = \ddnode{1}
  \end{gather}
  and $j = \mddLevel(\ddnode{n}) - 1$, i.e.~$\mddBelow(\ddnode{n})$ is
  the set of all paths in the \textls{MDD} leading from $\ddnode{n}$
  to $\ddnode{1}$.
\end{dfn}

The relation $\loc{\sim}{j}$ over $\loc{\RS}{j}$ can be expressed
with $\mddAbove(\ddnode{n})$ and $\mddBelow(\ddnode{n})$ is a way that
can be handled easily with symbolic techniques.

\begin{obs}
  \label{obs:genstor:symbolic:block:paths}
  The set of states which contain some local state $\loc{x}{j}$ is
  \begin{multline}
    \{\loc{\hat{\vec{z}}}{j} : \vec{z} \in \RS, \loc{z}{j} = \loc{x}{j}\} =\\ \{
    (\vec{b},\vec{a}) : \ddnode{n} \in V_{j + 1},
    \mddChildren(\ddnode{n}, \loc{x}{j}) \ne \ddnode{n}, \vec{b} \in
    \mddBelow(\mddChildren(\ddnode{n}, \loc{x}{j})), \vec{a} \in
    \mddAbove(\ddnode{n}) \} \text.
  \end{multline}
\end{obs}

\begin{proof}
  Any reachable state $\vec{z} \in \RS$ that has
  $\loc{z}{j} = \loc{x}{j}$ is represented by a path in the
  \textls{MDD} that passes through a pair of nodes
  $\ddnode{n} \in V_{j + 1}$ and
  $\mddChildren(\ddnode{n}, \loc{x}{j}) \ne \ddnode{0}$. Therefore,
  some path $\vec{a} \in \mddAbove(\ddnode{n})$ must be followed from
  $\ddnode{r}$ to reach $\ddnode{n}$, then some path
  $\vec{b} \in \mddBelow(\mddChildren(\ddnode{n}, \loc{x}{j}))$ must
  be followed from $\mddChildren(\ddnode{n}, \loc{x}{j})$ to
  $\ddnode{1}$.

  This means all paths from $\ddnode{r}$ to $\ddnode{1}$ containing
  $\loc{x}{j}$ are of the form $(\vec{b}, \loc{x}{j}, \vec{a})$ and
  the converse also holds.
\end{proof}

\begin{figure}
  \centering
  \begin{tikzpicture}[
    ddnode/.style={
      draw,tdk highlight,
      rectangle split,
      rectangle split parts=#1,
      rectangle split horizontal,
      inner sep=5pt
    },
    terminal/.style={
      draw,circle,tdk highlight
    }
    ]

    \matrix [row sep=1.2cm,column sep=1cm,node distance=1cm] {
      \node {$V_3:$};
      & \node [ddnode=2] (x00) {0\nodepart{two}1}; \\
      \node {$V_2:$};
      & \node [ddnode=3] (x10) {0\nodepart{two}1\nodepart{three}2};
      & \node [ddnode=3] (x11) {0\nodepart{two}1\nodepart{three}2}; \\
      \node {$V_1:$};
      & \node [ddnode=3] (x20) {0\nodepart{two}1\nodepart{three}2};
      & \node [ddnode=3] (x21) {0\nodepart{two}1\nodepart{three}2}; \\
      \node {$V_0:$};
      & \node [terminal] (t0) {$\ddnode{0}$};
      & \node [terminal] (t1) {$\ddnode{1}$}; \\
    };

    \begin{scope}[
      every edge/.append style={-{Latex}},
      every node/.append style={above}
      ]
      \draw (x00.one south) edge node [right] {0} (x10);
      \draw [very thick, dashed] (x00.two south) edge node [above] {4} (x11);
      \draw (x10.one south) edge node [left] {0} (x20);
      \draw (x10.two south) edge node [right] {2} (x20);
      \draw (x11.one south) edge node [left,yshift=-5pt,xshift=2pt] {0} (x21);
      \draw (x11.two south) edge node [right] {1} (x21);
      \draw [very thick] (x11.three south) edge node [left,yshift=5pt] {2} (x20);
      \draw [very thick, dotted] (x20.one south) edge node [below,xshift=-5pt] {0} (t1);
      \draw [very thick, dotted] (x20.two south) edge node [xshift=5pt] {1} (t1);
      \draw (x21.three south) edge node [right] {0} (t1);
    \end{scope}
  \end{tikzpicture}
  \caption{The set of all paths having $\loc{x}{1} = \loc{2}{1}$ in
    the \emph{SharedResource} \textls{EDD}.}
  \label{fig:genstor:symbolic:edd-bind-variable}
\end{figure}

\begin{runningExample}
  \Cref{fig:genstor:symbolic:edd-bind-variable} shows all path in the
  \emph{SharedResource} \textls{MDD} with $\loc{x}{1} = \loc{2}{1}$.

  The single path in the set $\mddAbove(\ddnode{n})$ is dashed, while
  paths in the set $\mddBelow(\mddChildren(\ddnode{n}, \loc{2}{1}))$ are
  drawn as dotted edges.
\end{runningExample}

\begin{obs}
  If $\ddnode{n}$ and $\ddnode{m}$ are distinct nonterminal nodes of a
  quasi-reduced ordered \textls{MDD},
  $\mddAbove(\ddnode{n}) \cup \mddAbove(\ddnode{m}) = \emptyset$ and
  $\mddBelow(\ddnode{n}) \ne \mddBelow(\ddnode{m})$.
\end{obs}

\begin{proof}
  We prove the statements indirectly. Let
  $\vec{a} \in \mddAbove(\ddnode{n}) \cup \mddAbove(\ddnode{m})$. If we
  follow the path $\vec{a}$ for $\ddnode{r}$, we arrive at
  $\ddnode{n}$, because $\vec{a} \in \mddAbove(\ddnode{n})$. However, we
  also arrive at $\ddnode{m}$, because
  $\vec{a} \in Above(\ddnode{m})$. This is a contradition, since
  $\ddnode{n} \ne \ddnode{m}$, $\mddAbove(\ddnode{n})$ and
  $\mddAbove(\ddnode{m}$ must be disjoint.

  Now suppose that there are $\ddnode{n}, \ddnode{m} \in V_N$ such
  that $\mddBelow(\ddnode{n}) = \mddBelow(\ddnode{m})$. Because the paths
  $\mddBelow(\ddnode{n})$ describe the subgraph reachable from
  $\ddnode{n}$ completely, this means the subgraphs reachable from
  $\ddnode{n}$ and $\ddnode{m}$ are isomorphic. This is impossible,
  because then the \textls{MDD} cannot be reduced, thus
  $\mddBelow(\ddnode{n})$ and $\mddBelow(\ddnode{m})$ must be distinct.
\end{proof}

\begin{obs}
  \label{obs:genstor:symbolic:parallel-edges}
  The relation $\loc{x}{j} \mathbin{\loc{\sim}{j}} \loc{y}{j}$ can be
  expressed as
  \begin{multline}
    \loc{x}{j} \mathbin{\loc{\sim}{j}} \loc{y}{j}
    \quad\Longleftrightarrow\\
    \{ (\ddnode{n}, \mddChildren(\ddnode{n}, \loc{x}{j})) : \ddnode{n}
    \in V_{j + 1} \} = \{ (\ddnode{n}, \mddChildren(\ddnode{n},
    \loc{y}{j})) : \ddnode{n} \in V_{j + 1} \} \text.
  \end{multline}
\end{obs}

\begin{proof}
  Let
  \begin{align}
    X &= \{ \loc{\hat{\vec{z}}}{j} : \vec{z} \in \RS, \loc{z}{j} =
        \loc{x}{j} \},
    & Y &= \{ \loc{\hat{\vec{z}}}{j} : \vec{z} \in \RS, \loc{z}{j} =
        \loc{y}{j} \}.
  \end{align}
  According to \vref{eq:genstor:explicit:block:locsim}, $\loc{x}{j}
  \mathbin{\loc{\sim}{j}} \loc{y}{j}$ if and only if $X = Y$.

  Define
  \begin{align}
    X(\ddnode{n}) &= \{ \vec{b} : (\vec{b}, \vec{a}) \in X, \vec{b} \in
    \mddAbove(\ddnode{n}) \},
    & Y(\ddnode{n}) &= \{ \vec{b} : (\vec{b}, \vec{a}) \in Y, \vec{b} \in
    \mddAbove(\ddnode{n}) \} \text.
  \end{align}
  $X = Y$ holds precisely when
  $X(\ddnode{n}) = Y(\ddnode{n})$ for all $\ddnode{n} \in V_{j + 1}$.
  We may notice that $\{X(\ddnode{n}) \times
  \mddAbove(\ddnode{n})\}_{\ddnode{n} \in V_{j + 1}}$ and
  $\{Y(\ddnode{n}) \times
  \mddAbove(\ddnode{n})\}_{\ddnode{n} \in V_{j + 1}}$ are partitions of $X$
  and $Y$, respectively, because the $\mddAbove$-sets are disjoint for
  each node.

  According to \cref{obs:genstor:symbolic:block:paths},
  \begin{align}
    X(\ddnode{n}) &= \mddBelow(\mddChildren(\ddnode{n}, \loc{x}{j})),
    & Y(\ddnode{n}) &= \mddBelow(\mddChildren(\ddnode{n}, \loc{y}{j}))
                      \text.
  \end{align}
  Thus, $X(\ddnode{n}) = Y(\ddnode{n})$ if and only if
  $\mddChildren(\ddnode{n}, \loc{x}{j}) = \mddChildren(\ddnode{n},
  \loc{y}{j})$,
  because the $\mddBelow$-sets are distinct for each node.
\end{proof}

\Cref{obs:genstor:symbolic:parallel-edges} can be interpreted as the
statement that $\loc{x}{j} \mathbin{\loc{\sim}{j}} \loc{y}{j}$ if and
only if the \textls{MDD} edges corresponding to $\loc{x}{j}$ are
always parallel, i.e.~from the node $\ddnode{n}$ they all go to the
same node $\ddnode{m}(\ddnode{n})$ for all $\ddnode{n} \in V_{j + 1}$.

\begin{algorithm}
  \KwIn{Symbolic state space $\MDD$}
  \KwOut{Local macro states $\loc{\Macro{\RS}}{j}$, $\loc{\RS}{j}_x$}
  \For{$j \gets 0$ \KwTo $J - 1$}{
    Initialize the empty queue $Q$\;
    $\textit{Done} \gets \{\loc{\RS}{j}\}$\;
    \ForEach{$\ddnode{n} \in V_{j + 1}$}{
      \ForEach{$S \in \textit{Done}$}{$\textsc{Enqueue}(Q, S)$}
      $\textit{Done} \gets \emptyset$\;
      \While{$\neg \textsc{Empty}(Q)$}{
        $S \gets \textsc{Dequeue}(Q)$\;
        $S_1 \gets \emptyset$\;
        $S_2 \gets \emptyset$\;
        Let $x_0$ be any element of $S$\;
        $\ddnode{m} \gets \mddChildren(\ddnode{n}, x_0)$\;
        \ForEach{$x \in S \setminus \{ x_0 \}$}{
          \leIf{$\ddnode{m} = \mddChildren(\ddnode{n}, x)$}{%
            \label{ln:genstor:symbolic:refinement:split}
            $S_1 \gets S_1 \cup \{x\}$%
          }{%
            $S_2 \gets S_2 \cup \{x\}$%
          }
        }
        \If{$S_2 \ne \emptyset$}{%
          $\textsc{Enqueue}(Q, S_2)$
        }
        $\textit{Done} \gets \textit{Done} \cup \{S_1\}$\;
      }
    }
    $\macro{n}_j \gets \lvert \textit{Done} \rvert$\;
    $\loc{\Macro{\RS}}{j} \gets \{\loc{\macro{0}}{j},
    \loc{\macro{1}}{j}, \ldots, \loc{\Macro{\macro{n}_j - 1}}{j}\}$\;
    Each set $S \in \textit{Done}$ is a local macro state
    $\loc{\Macro{\RS}}{j}_x$\;
  }
  \caption{Local macro state construction by partition refinement.}
  \label{alg:genstor:symbolic:refinement}
\end{algorithm}

The macro states can be constructed from the paralell edges in the
\textls{MDD} by partition refinement. This process is performed by
\vref{alg:genstor:symbolic:refinement}.

The key step in partition refinement is in line%
~\ref{ln:genstor:symbolic:refinement:split}, where the candiate macro
state $S$ is split into $S_1$ and $S_2$. Edges in $S_1$ are all
parallel and go from
$\ddnode{n}$ to $\ddnode{m}$, while $S_2$ is further split. The
process is repeated for each node $\ddnode{n}$ and level $V_{j + 1}$
until only parallel macro state candidates remain.

This procedure is based on an idea of \citet{buchholz2004kronecker},
however, we employed partition refinement instead of hashing and and
proved correctness of the algorithm formally.

A block Kronecker matrix may be constructed from the decomposed state
space by \cref{alg:genstor:explicit:block:construction}.

\section{Matrix storage}

Existing linear algebra and matrix libraries, such as%
~\citep{mathdotnet,bluebit,extremeopt,eigen,sanderson2010armadillo},
usually have unsatisfactory support for operations required in
stochastic analysis algorithms with decomposed matrices, for example,
multiplications with Kronecker and block Kronecker
matrices. Therefore, we have decided to develop a linear algebra
framework in C\#.NET specifically for stochastic
algorithms as a basis of our stochastic analysis framework.

\begin{figure}
  \centering
  \begin{minipage}{0.5\linewidth}
    \begin{equation}
      A = \
      \begin{pmatrix}
        1 & 0 & 0 & 2.5 \\
        3 & 1 & 0 & 0 \\
        4 & 0 & 0 & 1 \\
        5 & 0 & 0 & 0
      \end{pmatrix}
    \end{equation}
  \end{minipage}%
  \begin{minipage}{0.5\linewidth}
    \begin{align}
      A = \{&\{(1,0), (3,1), (4,2), (5,3)\}, \\
      &\{(1,1)\}, \\
      &\{\}, \\
      &\{(2.5,0), (1,2)\}\}
    \end{align}
  \end{minipage}
  \caption{Compressed Column Storage of a matrix.}
  \label{fig:genstor:matrix:ccs}
\end{figure}

Sparse matrices are stored in Compressed Column Storage (\textls{CCS})
format, i.e.~an array or values and row indices are stored for each
column of the matrix, as illustrated in
\cref{fig:genstor:matrix:ccs}. This facilitates multiplication from
left with row vectors. To reduce pressure on the garbage collector
(\textls{GC}), matrices are vectors are stored in manually allocated
and managed memory.

While other sparse matrix formats, such as sliced \textls{LAPACK} are
more amenable to parallel and \textls{SIMD} processing
\citet{DBLP:journals/corr/KreutzerHWFB13}, \textls{CCS} was selected
due to implementation simplicity and the small number of nonzero
entries in each column of the matrix, which reduces the potential
benefits of \textls{SIMD} implementations.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \matrix [every node/.append style={
      text width=2.1cm,minimum height=1.2cm,align=center,
      draw,tdk highlight
    },column sep=1cm,row sep=0.3cm] {
      \node (block) {Block\\Matrix}; & \node (lin) {Linear\\Combination};
      & \node (kr) {Kronecker\\Matrix}; & \node (sparse) {Sparse\\Matrix}; \\
      & & & \node (id) {Identity\\Matrix}; \\
      & & \node (diag) {Diagonal Matrix}; & \node (vec) {Vector}; \\
    };
    \draw [{Diamond[length=10pt]}-,
    every node/.append style={at end,above,anchor=south east}]
    (block) edge node {$\ast$} (lin) (lin) edge node {$\ast$} (kr)
    (kr) edge node {$\ast$} (sparse)
    (diag) edge node [below,anchor=north east,yshift=-1] {1} (vec);
    \draw [every node/.append style={at end,below,anchor=north east,yshift=-1pt}]
    ($(lin.east)+(0.5cm,0)$) |- node {0..1} (diag)
    ($(kr.east)+(0.5cm,0)$) |- node {$\ast$} (id);
  \end{tikzpicture}
  \caption{Data structure for block Kronecker matrices.}
  \label{fig:genstor:kronecker:datastructure}
\end{figure}

Decomposed Kronecker and block Kronecker matrices are stored as
algebraic expression trees as shown in
\cref{fig:genstor:kronecker:datastructure}. Matrix multiplication
and manipulation algorithms for expression trees are detailed in
\vref{sec:algorithms:vector-matrix}.

The expression tree approach allows the use of arbitrary matrix
decompositions that can be expressed with block matrices, linear
combinations and Kronecker products. The implementation of additional
opeartional primitives is also straightforward. The data structure
forms a flexible basis for the development of stochastic analysis
algorithms with decomposed matrix representations.